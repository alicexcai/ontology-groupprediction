{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import multitest\n",
    "from scipy import stats\n",
    "from scipy.stats import levene, norm\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_rgb\n",
    "import colorsys\n",
    "import itertools\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "colors = plt.colormaps[\"Dark2\"].colors\n",
    "from tqdm import tqdm\n",
    "\n",
    "# silence warnings because the NN has a lot of them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from optuna import create_study\n",
    "from optuna.trial import Trial\n",
    "from tensorflow.keras import backend as K\n",
    "import random\n",
    "\n",
    "# for saving model params\n",
    "import pickle\n",
    "\n",
    "# for feature importance\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import copy\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONDITION-LEVEL DATA\n",
    "df_condition_level_data = pd.read_csv('../outputs/condition_level_group_advantage_with_ivs.csv') # mark's version of the cleaning\n",
    "\n",
    "# add in categorical task types\n",
    "df_condition_data_with_mcgrath_types = pd.read_csv('../outputs/condition_level_group_advantage_with_ivs_and_categories.csv')\n",
    "mcgrath_cols = df_condition_data_with_mcgrath_types.filter(like=\"Type\").columns\n",
    "df_condition_data_with_mcgrath_types = df_condition_data_with_mcgrath_types[[\"task\"] + list(mcgrath_cols)].drop_duplicates()\n",
    "# rename the mcgrath columns to have the suffix \"_categorical\"\n",
    "df_condition_data_with_mcgrath_types = df_condition_data_with_mcgrath_types.rename(columns={col: col + \"_categorical\" for col in mcgrath_cols})\n",
    "df_condition_level_data = df_condition_level_data.merge(df_condition_data_with_mcgrath_types, on=\"task\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>strong</th>\n",
       "      <th>High</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Putting Food Into Categories</td>\n",
       "      <td>1.659080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Word Construction</td>\n",
       "      <td>1.627765</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Unscramble Words</td>\n",
       "      <td>1.627760</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Putting Food Into Categories</td>\n",
       "      <td>1.606875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Putting Food Into Categories</td>\n",
       "      <td>1.534374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advertisement Writing</td>\n",
       "      <td>0.443447</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advertisement Writing</td>\n",
       "      <td>0.417235</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Whac a Mole</td>\n",
       "      <td>0.331275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Dot Motion</td>\n",
       "      <td>0.297844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Whac a Mole</td>\n",
       "      <td>0.261190</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             task    strong  High  Medium  Low\n",
       "39   Putting Food Into Categories  1.659080     0       1    0\n",
       "113             Word Construction  1.627765     1       0    0\n",
       "80               Unscramble Words  1.627760     0       1    0\n",
       "37   Putting Food Into Categories  1.606875     0       0    1\n",
       "41   Putting Food Into Categories  1.534374     1       0    0\n",
       "..                            ...       ...   ...     ...  ...\n",
       "5           Advertisement Writing  0.443447     1       0    0\n",
       "3           Advertisement Writing  0.417235     0       1    0\n",
       "89                    Whac a Mole  0.331275     1       0    0\n",
       "45              Random Dot Motion  0.297844     0       1    0\n",
       "87                    Whac a Mole  0.261190     0       1    0\n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect data, just to get a sense of the range of values.\n",
    "df_condition_level_data[[\"task\", \"strong\", \"High\", \"Medium\", \"Low\"]].sort_values(\"strong\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_observation_level_data = pd.read_csv('../outputs/observation_level_dv_with_composition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOCAL_DEMOGRAPHIC_COLS = ['IRCS_GS', 'IRCS_GV', 'IRCS_IB', 'IRCS_IR', 'IRCS_IV', 'IRCS_RS',\n",
    "                        'RME', 'CRT', 'birth_year', 'education_level', 'income_max', 'political_fiscal', 'political_party', 'political_social',\n",
    "                        'gender', 'race', 'marital_status']\n",
    "\n",
    "COMPOSITION_IVS = [col for col in df_observation_level_data.columns if any(col.startswith(prefix) for prefix in FOCAL_DEMOGRAPHIC_COLS)]\n",
    "COMPOSITION_IVS = COMPOSITION_IVS + [\"playerCount\", \"Low\", \"Medium\", \"High\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-value check: Within-Task Type Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"...there is almost as much within-category variation as exists overall.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>cat_col</th>\n",
       "      <th colspan=\"3\" halign=\"left\">strong</th>\n",
       "      <th colspan=\"3\" halign=\"left\">weak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Type 2 (Generate)_categorical</td>\n",
       "      <td>1.040283</td>\n",
       "      <td>0.333841</td>\n",
       "      <td>30</td>\n",
       "      <td>1.725222</td>\n",
       "      <td>0.808108</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type 3 (Intellective)_categorical</td>\n",
       "      <td>0.953430</td>\n",
       "      <td>0.227294</td>\n",
       "      <td>66</td>\n",
       "      <td>1.547579</td>\n",
       "      <td>0.586886</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type 4 (Decision-Making)_categorical</td>\n",
       "      <td>0.689811</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>6</td>\n",
       "      <td>1.024908</td>\n",
       "      <td>0.122569</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Type 5 (Cognitive Conflict)_categorical</td>\n",
       "      <td>0.671171</td>\n",
       "      <td>0.104386</td>\n",
       "      <td>6</td>\n",
       "      <td>1.207868</td>\n",
       "      <td>0.117462</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Type 8 (Performance)_categorical</td>\n",
       "      <td>0.837984</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>12</td>\n",
       "      <td>1.521116</td>\n",
       "      <td>0.608324</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cat_col    strong                  \\\n",
       "                                                mean       std count   \n",
       "0            Type 2 (Generate)_categorical  1.040283  0.333841    30   \n",
       "1        Type 3 (Intellective)_categorical  0.953430  0.227294    66   \n",
       "2     Type 4 (Decision-Making)_categorical  0.689811  0.060508     6   \n",
       "3  Type 5 (Cognitive Conflict)_categorical  0.671171  0.104386     6   \n",
       "4         Type 8 (Performance)_categorical  0.837984  0.366415    12   \n",
       "\n",
       "       weak                  \n",
       "       mean       std count  \n",
       "0  1.725222  0.808108    30  \n",
       "1  1.547579  0.586886    66  \n",
       "2  1.024908  0.122569     6  \n",
       "3  1.207868  0.117462     6  \n",
       "4  1.521116  0.608324    12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean       0.936305\n",
       "std        0.280842\n",
       "min        0.261190\n",
       "25%        0.801759\n",
       "50%        0.920559\n",
       "75%        1.001102\n",
       "max        1.659080\n",
       "Name: strong, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean       1.546224\n",
       "std        0.640559\n",
       "min        0.587855\n",
       "25%        1.116857\n",
       "50%        1.304525\n",
       "75%        1.720179\n",
       "max        3.730325\n",
       "Name: weak, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>cat_col</th>\n",
       "      <th colspan=\"3\" halign=\"left\">strong</th>\n",
       "      <th colspan=\"3\" halign=\"left\">weak</th>\n",
       "      <th>strong_W_stat</th>\n",
       "      <th>strong_p_value</th>\n",
       "      <th>weak_W_stat</th>\n",
       "      <th>weak_p_value</th>\n",
       "      <th>df1</th>\n",
       "      <th>df2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Type 2 (Generate)_categorical</td>\n",
       "      <td>1.040283</td>\n",
       "      <td>0.333841</td>\n",
       "      <td>30</td>\n",
       "      <td>1.725222</td>\n",
       "      <td>0.808108</td>\n",
       "      <td>30</td>\n",
       "      <td>1.011807</td>\n",
       "      <td>0.316112</td>\n",
       "      <td>2.139709</td>\n",
       "      <td>0.145649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Type 3 (Intellective)_categorical</td>\n",
       "      <td>0.953430</td>\n",
       "      <td>0.227294</td>\n",
       "      <td>66</td>\n",
       "      <td>1.547579</td>\n",
       "      <td>0.586886</td>\n",
       "      <td>66</td>\n",
       "      <td>3.383290</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.514379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Type 4 (Decision-Making)_categorical</td>\n",
       "      <td>0.689811</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>6</td>\n",
       "      <td>1.024908</td>\n",
       "      <td>0.122569</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Type 5 (Cognitive Conflict)_categorical</td>\n",
       "      <td>0.671171</td>\n",
       "      <td>0.104386</td>\n",
       "      <td>6</td>\n",
       "      <td>1.207868</td>\n",
       "      <td>0.117462</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Type 8 (Performance)_categorical</td>\n",
       "      <td>0.837984</td>\n",
       "      <td>0.366415</td>\n",
       "      <td>12</td>\n",
       "      <td>1.521116</td>\n",
       "      <td>0.608324</td>\n",
       "      <td>12</td>\n",
       "      <td>3.606798</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.074308</td>\n",
       "      <td>0.785598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cat_col    strong                  \\\n",
       "                                                mean       std count   \n",
       "0            Type 2 (Generate)_categorical  1.040283  0.333841    30   \n",
       "1        Type 3 (Intellective)_categorical  0.953430  0.227294    66   \n",
       "2     Type 4 (Decision-Making)_categorical  0.689811  0.060508     6   \n",
       "3  Type 5 (Cognitive Conflict)_categorical  0.671171  0.104386     6   \n",
       "4         Type 8 (Performance)_categorical  0.837984  0.366415    12   \n",
       "\n",
       "       weak                 strong_W_stat strong_p_value weak_W_stat  \\\n",
       "       mean       std count                                            \n",
       "0  1.725222  0.808108    30      1.011807       0.316112    2.139709   \n",
       "1  1.547579  0.586886    66      3.383290       0.067472    0.426800   \n",
       "2  1.024908  0.122569     6           NaN            NaN         NaN   \n",
       "3  1.207868  0.117462     6           NaN            NaN         NaN   \n",
       "4  1.521116  0.608324    12      3.606798       0.059760    0.074308   \n",
       "\n",
       "  weak_p_value  df1    df2  \n",
       "                            \n",
       "0     0.145649  1.0  148.0  \n",
       "1     0.514379  1.0  184.0  \n",
       "2          NaN  NaN    NaN  \n",
       "3          NaN  NaN    NaN  \n",
       "4     0.785598  1.0  130.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mcgrath_cat_cols = df_condition_data_with_mcgrath_types.filter(like=\"_cat\").columns\n",
    "cat_col = df_condition_level_data[mcgrath_cat_cols].idxmax(axis=1)\n",
    "df_condition_level_data_with_cat = df_condition_level_data.assign(cat_col=cat_col)\n",
    "\n",
    "# Aggregate and summarize data by category\n",
    "categorical_condition_summary = df_condition_level_data_with_cat.groupby(\"cat_col\").agg({\n",
    "    \"strong\": [\"mean\", \"std\", \"count\"],\n",
    "    \"weak\": [\"mean\", \"std\", \"count\"]\n",
    "}).reset_index()\n",
    "\n",
    "# categorical level summary\n",
    "display(categorical_condition_summary)\n",
    "\n",
    "# display the strong and weak values for the entire dataset\n",
    "display(df_condition_level_data[\"strong\"].describe())\n",
    "display(df_condition_level_data[\"weak\"].describe())\n",
    "\n",
    "strong_vals = df_condition_level_data[\"strong\"]\n",
    "weak_vals = df_condition_level_data[\"weak\"]\n",
    "\n",
    "strong_test_stats = []\n",
    "weak_test_stats = []\n",
    "strong_p_vals = []\n",
    "weak_p_vals = []\n",
    "df1_list = []\n",
    "df2_list = []\n",
    "\n",
    "# Iterate over each unique category to apply Levene's test\n",
    "for cat in categorical_condition_summary['cat_col']:\n",
    "    category_data = df_condition_level_data_with_cat[df_condition_level_data_with_cat['cat_col'] == cat]\n",
    "    \n",
    "    if category_data[\"strong\"].count() > 6:\n",
    "        cat_strong_vals = category_data[\"strong\"]\n",
    "        cat_weak_vals = category_data[\"weak\"]\n",
    "\n",
    "        # Levene's test comparing group variance to overall variance\n",
    "        \"\"\"\n",
    "        The Levene test tests the null hypothesis that all input samples \n",
    "        are from populations with equal variances. Leveneâ€™s test is an \n",
    "        alternative to Bartlettâ€™s test bartlett in the case where there \n",
    "        are significant deviations from normality.\n",
    "\n",
    "        Reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html\n",
    "\n",
    "        \"\"\"\n",
    "        W_stat_strong, p_val_strong = levene(cat_strong_vals, strong_vals)\n",
    "        W_stat_weak, p_val_weak = levene(cat_weak_vals, weak_vals)\n",
    "\n",
    "        # degrees of freedom\n",
    "        \"\"\"\n",
    "        The degree of freedom df1 is obtained by calculating the number of groups minus 1,\n",
    "        the degree of freedom df2 is obtained by calculating the number of cases minus the \n",
    "        number of groups.  Source: https://datatab.net/tutorial/levene-test\n",
    "        \"\"\"\n",
    "        NUM_GROUPS = 2\n",
    "        df1_list.append(NUM_GROUPS - 1)\n",
    "        df2_list.append(len(cat_strong_vals) + len(strong_vals) - NUM_GROUPS)\n",
    "        assert(len(cat_weak_vals) == len(cat_strong_vals)) # means we only need to calculate df once\n",
    "        assert(len(strong_vals) == len(weak_vals))\n",
    "\n",
    "        strong_test_stats.append(W_stat_strong)\n",
    "        weak_test_stats.append(W_stat_weak)\n",
    "        strong_p_vals.append(p_val_strong)\n",
    "        weak_p_vals.append(p_val_weak)\n",
    "    else:\n",
    "        strong_test_stats.append(None)\n",
    "        weak_test_stats.append(None)\n",
    "        strong_p_vals.append(None)\n",
    "        weak_p_vals.append(None)\n",
    "        df1_list.append(None)\n",
    "        df2_list.append(None)\n",
    "\n",
    "result_summary = categorical_condition_summary.assign(\n",
    "    strong_W_stat=strong_test_stats, \n",
    "    strong_p_value=strong_p_vals, \n",
    "    weak_W_stat=weak_test_stats, \n",
    "    weak_p_value=weak_p_vals,\n",
    "    df1 = df1_list,\n",
    "    df2 = df2_list\n",
    ")\n",
    "display(result_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity interaction patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in Whac-A-Mole, groups display weak advantage at low levels of complexity, but their advantage decreases as the complexity increases. Likewise, the Putting Food into Categories task shows a strong interaction with group size, in which larger groups demonstrate more advantage than smaller ones, regardless of the level of complexity. But all of these interaction patterns are heterogeneous across the 20 tasks in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Results for Task: Unscramble Words ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:              MixedLM  Dependent Variable:  strong  \n",
      "No. Observations:   159      Method:              REML    \n",
      "No. Groups:         53       Scale:               0.1029  \n",
      "Min. group size:    3        Log-Likelihood:      -51.8359\n",
      "Max. group size:    3        Converged:           No      \n",
      "Mean group size:    3.0                                   \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.202    0.101 11.920 0.000  1.004  1.400\n",
      "task_complexity  0.083    0.031  2.674 0.008  0.022  0.144\n",
      "playerCount     -0.023    0.017 -1.363 0.173 -0.057  0.010\n",
      "playerIds Var    0.000    0.039                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  159     Method:             REML     \n",
      "No. Groups:        53      Scale:              0.5668   \n",
      "Min. group size:   3       Log-Likelihood:     -185.0840\n",
      "Max. group size:   3       Converged:          No       \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       1.318    0.237 5.559 0.000  0.853  1.783\n",
      "task_complexity 0.291    0.073 3.973 0.000  0.147  0.434\n",
      "playerCount     0.094    0.040 2.336 0.019  0.015  0.172\n",
      "playerIds Var   0.002                                   \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Writing Story ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "=========================================================\n",
      "Model:              MixedLM  Dependent Variable:  strong \n",
      "No. Observations:   171      Method:              REML   \n",
      "No. Groups:         57       Scale:               0.0137 \n",
      "Min. group size:    3        Log-Likelihood:      97.1743\n",
      "Max. group size:    3        Converged:           Yes    \n",
      "Mean group size:    3.0                                  \n",
      "---------------------------------------------------------\n",
      "                Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------\n",
      "Intercept       0.900    0.043 20.745 0.000  0.815  0.985\n",
      "task_complexity 0.015    0.011  1.358 0.174 -0.007  0.036\n",
      "playerCount     0.002    0.008  0.236 0.814 -0.014  0.018\n",
      "playerIds Var   0.004    0.017                           \n",
      "=========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:               MixedLM  Dependent Variable:  weak   \n",
      "No. Observations:    171      Method:              REML   \n",
      "No. Groups:          57       Scale:               0.0188 \n",
      "Min. group size:     3        Log-Likelihood:      71.2585\n",
      "Max. group size:     3        Converged:           Yes    \n",
      "Mean group size:     3.0                                  \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.141    0.050 22.685 0.000  1.042  1.239\n",
      "task_complexity -0.049    0.013 -3.794 0.000 -0.074 -0.024\n",
      "playerCount      0.008    0.009  0.877 0.381 -0.010  0.027\n",
      "playerIds Var    0.005    0.019                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: WildCam ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  183      Method:              REML     \n",
      "No. Groups:        61       Scale:               0.2025   \n",
      "Min. group size:   3        Log-Likelihood:      -138.1058\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.024    0.163  6.298 0.000  0.705  1.342\n",
      "task_complexity -0.012    0.041 -0.283 0.777 -0.091  0.068\n",
      "playerCount     -0.024    0.030 -0.780 0.435 -0.083  0.036\n",
      "playerIds Var    0.058    0.063                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  183     Method:             REML     \n",
      "No. Groups:        61      Scale:              0.5824   \n",
      "Min. group size:   3       Log-Likelihood:     -230.5209\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       1.197    0.267 4.491 0.000  0.675  1.720\n",
      "task_complexity 0.043    0.069 0.627 0.531 -0.092  0.179\n",
      "playerCount     0.044    0.049 0.897 0.370 -0.052  0.141\n",
      "playerIds Var   0.137    0.097                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Typing ****\n",
      "===Strong Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: strong   \n",
      "No. Observations:  159     Method:             REML     \n",
      "No. Groups:        53      Scale:              0.0912   \n",
      "Min. group size:   3       Log-Likelihood:     -101.5623\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.869    0.245 3.545 0.000  0.388  1.350\n",
      "task_complexity 0.012    0.029 0.423 0.672 -0.045  0.070\n",
      "playerCount     0.056    0.051 1.094 0.274 -0.044  0.156\n",
      "playerIds Var   0.280    0.248                          \n",
      "========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  159     Method:             REML     \n",
      "No. Groups:        53      Scale:              0.3130   \n",
      "Min. group size:   3       Log-Likelihood:     -195.2208\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.951    0.433 2.193 0.028  0.101  1.800\n",
      "task_complexity 0.070    0.054 1.289 0.197 -0.036  0.177\n",
      "playerCount     0.203    0.090 2.259 0.024  0.027  0.380\n",
      "playerIds Var   0.859    0.415                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Recall Association ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  183      Method:              REML     \n",
      "No. Groups:        61       Scale:               0.1039   \n",
      "Min. group size:   3        Log-Likelihood:      -108.6354\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.247    0.179  6.968 0.000  0.896  1.597\n",
      "task_complexity  0.093    0.029  3.202 0.001  0.036  0.151\n",
      "playerCount     -0.007    0.037 -0.181 0.856 -0.078  0.065\n",
      "playerIds Var    0.148    0.127                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  183     Method:             REML     \n",
      "No. Groups:        61      Scale:              0.3424   \n",
      "Min. group size:   3       Log-Likelihood:     -215.9833\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       1.645    0.325 5.062 0.000  1.008  2.281\n",
      "task_complexity 0.136    0.053 2.576 0.010  0.033  0.240\n",
      "playerCount     0.178    0.066 2.686 0.007  0.048  0.309\n",
      "playerIds Var   0.487    0.231                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Advertisement Writing ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  182      Method:              REML     \n",
      "No. Groups:        61       Scale:               0.3472   \n",
      "Min. group size:   2        Log-Likelihood:      -174.7540\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.894    0.187  4.795 0.000  0.529  1.260\n",
      "task_complexity  0.072    0.054  1.341 0.180 -0.033  0.177\n",
      "playerCount     -0.098    0.033 -2.966 0.003 -0.163 -0.033\n",
      "playerIds Var    0.033    0.057                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak     \n",
      "No. Observations:  182      Method:              REML     \n",
      "No. Groups:        61       Scale:               1.9978   \n",
      "Min. group size:   2        Log-Likelihood:      -328.8096\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.217    0.435  2.800 0.005  0.365  2.069\n",
      "task_complexity  0.347    0.129  2.697 0.007  0.095  0.599\n",
      "playerCount     -0.120    0.076 -1.570 0.116 -0.269  0.030\n",
      "playerIds Var    0.120    0.125                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Moral Reasoning ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:              MixedLM  Dependent Variable:  strong  \n",
      "No. Observations:   174      Method:              REML    \n",
      "No. Groups:         58       Scale:               0.0773  \n",
      "Min. group size:    3        Log-Likelihood:      -64.4864\n",
      "Max. group size:    3        Converged:           Yes     \n",
      "Mean group size:    3.0                                   \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.666    0.128  5.190 0.000  0.414  0.917\n",
      "task_complexity -0.035    0.026 -1.345 0.179 -0.085  0.016\n",
      "playerCount      0.021    0.025  0.822 0.411 -0.029  0.070\n",
      "playerIds Var    0.057    0.069                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak     \n",
      "No. Observations:  174      Method:              REML     \n",
      "No. Groups:        58       Scale:               0.1705   \n",
      "Min. group size:   3        Log-Likelihood:      -130.9673\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.843    0.187  4.498 0.000  0.476  1.210\n",
      "task_complexity -0.038    0.038 -0.997 0.319 -0.113  0.037\n",
      "playerCount      0.057    0.037  1.561 0.119 -0.015  0.130\n",
      "playerIds Var    0.119    0.098                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Random Dot Motion ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:              MixedLM  Dependent Variable:  strong  \n",
      "No. Observations:   159      Method:              REML    \n",
      "No. Groups:         53       Scale:               0.1195  \n",
      "Min. group size:    3        Log-Likelihood:      -63.5136\n",
      "Max. group size:    3        Converged:           No      \n",
      "Mean group size:    3.0                                   \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.152    0.109 10.600 0.000  0.939  1.365\n",
      "task_complexity -0.089    0.034 -2.657 0.008 -0.155 -0.023\n",
      "playerCount     -0.052    0.018 -2.856 0.004 -0.088 -0.016\n",
      "playerIds Var    0.000    0.051                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak     \n",
      "No. Observations:  159      Method:              REML     \n",
      "No. Groups:        53       Scale:               0.2891   \n",
      "Min. group size:   3        Log-Likelihood:      -132.3515\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.286    0.169  7.612 0.000  0.955  1.617\n",
      "task_complexity -0.014    0.052 -0.269 0.788 -0.116  0.088\n",
      "playerCount     -0.058    0.028 -2.021 0.043 -0.113 -0.002\n",
      "playerIds Var    0.000    0.046                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Wildcat Wells ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:              MixedLM  Dependent Variable:  strong  \n",
      "No. Observations:   183      Method:              REML    \n",
      "No. Groups:         61       Scale:               0.0811  \n",
      "Min. group size:    3        Log-Likelihood:      -60.0070\n",
      "Max. group size:    3        Converged:           Yes     \n",
      "Mean group size:    3.0                                   \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.816    0.109  7.504 0.000  0.603  1.029\n",
      "task_complexity  0.018    0.026  0.699 0.485 -0.033  0.069\n",
      "playerCount     -0.023    0.021 -1.130 0.258 -0.064  0.017\n",
      "playerIds Var    0.031    0.046                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  183     Method:             REML     \n",
      "No. Groups:        61      Scale:              0.1970   \n",
      "Min. group size:   3       Log-Likelihood:     -140.3745\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.992    0.170 5.821 0.000  0.658  1.326\n",
      "task_complexity 0.034    0.040 0.853 0.394 -0.044  0.113\n",
      "playerCount     0.028    0.033 0.859 0.391 -0.036  0.092\n",
      "playerIds Var   0.078    0.073                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Word Construction ****\n",
      "===Strong Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:              MixedLM Dependent Variable: strong  \n",
      "No. Observations:   163     Method:             REML    \n",
      "No. Groups:         55      Scale:              0.1034  \n",
      "Min. group size:    1       Log-Likelihood:     -97.7992\n",
      "Max. group size:    3       Converged:          Yes     \n",
      "Mean group size:    3.0                                 \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.884    0.193 4.588 0.000  0.506  1.261\n",
      "task_complexity 0.147    0.031 4.755 0.000  0.086  0.208\n",
      "playerCount     0.043    0.039 1.107 0.268 -0.033  0.120\n",
      "playerIds Var   0.153    0.140                          \n",
      "========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  163     Method:             REML     \n",
      "No. Groups:        55      Scale:              0.6418   \n",
      "Min. group size:   1       Log-Likelihood:     -230.3148\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       1.027    0.384 2.671 0.008  0.273  1.780\n",
      "task_complexity 0.190    0.077 2.471 0.013  0.039  0.342\n",
      "playerCount     0.306    0.075 4.061 0.000  0.158  0.453\n",
      "playerIds Var   0.481    0.209                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Recall Word Lists ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  159      Method:              REML     \n",
      "No. Groups:        53       Scale:               0.1816   \n",
      "Min. group size:   3        Log-Likelihood:      -104.0600\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.039    0.148  7.009 0.000  0.749  1.330\n",
      "task_complexity -0.049    0.041 -1.174 0.241 -0.130  0.033\n",
      "playerCount     -0.008    0.026 -0.317 0.751 -0.060  0.043\n",
      "playerIds Var    0.022    0.047                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  159     Method:             REML     \n",
      "No. Groups:        53      Scale:              0.7321   \n",
      "Min. group size:   3       Log-Likelihood:     -213.2171\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       1.099    0.299 3.672 0.000  0.513  1.686\n",
      "task_complexity 0.148    0.083 1.775 0.076 -0.015  0.310\n",
      "playerCount     0.068    0.053 1.265 0.206 -0.037  0.172\n",
      "playerIds Var   0.095    0.096                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Room Assignment ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:               MixedLM  Dependent Variable:  strong \n",
      "No. Observations:    180      Method:              REML   \n",
      "No. Groups:          60       Scale:               0.0163 \n",
      "Min. group size:     3        Log-Likelihood:      44.6808\n",
      "Max. group size:     3        Converged:           Yes    \n",
      "Mean group size:     3.0                                  \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.910    0.086 10.545 0.000  0.741  1.080\n",
      "task_complexity -0.012    0.012 -1.008 0.313 -0.035  0.011\n",
      "playerCount      0.004    0.018  0.210 0.834 -0.032  0.039\n",
      "playerIds Var    0.038    0.077                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:              MixedLM Dependent Variable: weak    \n",
      "No. Observations:   180     Method:             REML    \n",
      "No. Groups:         60      Scale:              0.0367  \n",
      "Min. group size:    3       Log-Likelihood:     -22.2024\n",
      "Max. group size:    3       Converged:          Yes     \n",
      "Mean group size:    3.0                                 \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.895    0.120 7.465 0.000  0.660  1.130\n",
      "task_complexity 0.114    0.017 6.519 0.000  0.080  0.148\n",
      "playerCount     0.028    0.025 1.113 0.266 -0.021  0.077\n",
      "playerIds Var   0.071    0.098                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Sudoku ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:               MixedLM  Dependent Variable:  strong \n",
      "No. Observations:    165      Method:              REML   \n",
      "No. Groups:          55       Scale:               0.0351 \n",
      "Min. group size:     3        Log-Likelihood:      17.0145\n",
      "Max. group size:     3        Converged:           Yes    \n",
      "Mean group size:     3.0                                  \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.070    0.072 14.820 0.000  0.928  1.211\n",
      "task_complexity -0.062    0.018 -3.473 0.001 -0.097 -0.027\n",
      "playerCount     -0.007    0.013 -0.499 0.618 -0.033  0.019\n",
      "playerIds Var    0.010    0.028                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "=========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak    \n",
      "No. Observations:  165      Method:              REML    \n",
      "No. Groups:        55       Scale:               0.0575  \n",
      "Min. group size:   3        Log-Likelihood:      -21.8757\n",
      "Max. group size:   3        Converged:           Yes     \n",
      "Mean group size:   3.0                                   \n",
      "---------------------------------------------------------\n",
      "                Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------\n",
      "Intercept       1.031    0.091 11.330 0.000  0.853  1.209\n",
      "task_complexity 0.001    0.023  0.065 0.949 -0.043  0.046\n",
      "playerCount     0.016    0.017  0.943 0.345 -0.017  0.048\n",
      "playerIds Var   0.015    0.034                           \n",
      "=========================================================\n",
      "\n",
      "****Results for Task: Whac a Mole ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  184      Method:              REML     \n",
      "No. Groups:        62       Scale:               0.1509   \n",
      "Min. group size:   1        Log-Likelihood:      -114.7989\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.351    0.142  9.493 0.000  1.072  1.630\n",
      "task_complexity -0.107    0.035 -3.046 0.002 -0.176 -0.038\n",
      "playerCount     -0.131    0.028 -4.767 0.000 -0.185 -0.077\n",
      "playerIds Var    0.052    0.060                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak     \n",
      "No. Observations:  184      Method:              REML     \n",
      "No. Groups:        62       Scale:               0.5385   \n",
      "Min. group size:   1        Log-Likelihood:      -229.6262\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        2.231    0.268  8.334 0.000  1.707  2.756\n",
      "task_complexity -0.176    0.066 -2.652 0.008 -0.306 -0.046\n",
      "playerCount     -0.181    0.052 -3.494 0.000 -0.282 -0.079\n",
      "playerIds Var    0.182    0.111                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Guess the Correlation ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:              MixedLM  Dependent Variable:  strong  \n",
      "No. Observations:   175      Method:              REML    \n",
      "No. Groups:         59       Scale:               0.0720  \n",
      "Min. group size:    2        Log-Likelihood:      -27.4559\n",
      "Max. group size:    3        Converged:           Yes     \n",
      "Mean group size:    3.0                                   \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.974    0.082 11.893 0.000  0.813  1.134\n",
      "task_complexity -0.032    0.025 -1.274 0.202 -0.081  0.017\n",
      "playerCount     -0.012    0.014 -0.896 0.370 -0.040  0.015\n",
      "playerIds Var    0.001    0.022                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:              MixedLM  Dependent Variable:  weak    \n",
      "No. Observations:   175      Method:              REML    \n",
      "No. Groups:         59       Scale:               0.1541  \n",
      "Min. group size:    2        Log-Likelihood:      -92.3392\n",
      "Max. group size:    3        Converged:           Yes     \n",
      "Mean group size:    3.0                                   \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.253    0.119 10.522 0.000  1.020  1.486\n",
      "task_complexity -0.054    0.036 -1.472 0.141 -0.125  0.018\n",
      "playerCount      0.024    0.020  1.169 0.242 -0.016  0.063\n",
      "playerIds Var    0.002    0.031                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Putting Food Into Categories ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  183      Method:              REML     \n",
      "No. Groups:        61       Scale:               0.1099   \n",
      "Min. group size:   3        Log-Likelihood:      -118.7847\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.594    0.199  2.986 0.003  0.204  0.984\n",
      "task_complexity -0.038    0.030 -1.255 0.209 -0.096  0.021\n",
      "playerCount      0.180    0.041  4.394 0.000  0.100  0.261\n",
      "playerIds Var    0.193    0.155                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:             MixedLM Dependent Variable: weak     \n",
      "No. Observations:  183     Method:             REML     \n",
      "No. Groups:        61      Scale:              0.3143   \n",
      "Min. group size:   3       Log-Likelihood:     -211.3605\n",
      "Max. group size:   3       Converged:          Yes      \n",
      "Mean group size:   3.0                                  \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.324    0.326 0.992 0.321 -0.316  0.963\n",
      "task_complexity 0.014    0.051 0.282 0.778 -0.085  0.114\n",
      "playerCount     0.417    0.067 6.223 0.000  0.286  0.549\n",
      "playerIds Var   0.508    0.246                          \n",
      "========================================================\n",
      "\n",
      "****Results for Task: Logic Problem ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:               MixedLM  Dependent Variable:  strong \n",
      "No. Observations:    159      Method:              REML   \n",
      "No. Groups:          53       Scale:               0.0144 \n",
      "Min. group size:     3        Log-Likelihood:      96.0925\n",
      "Max. group size:     3        Converged:           Yes    \n",
      "Mean group size:     3.0                                  \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.094    0.040 27.109 0.000  1.015  1.173\n",
      "task_complexity -0.032    0.012 -2.701 0.007 -0.054 -0.009\n",
      "playerCount     -0.020    0.007 -2.902 0.004 -0.034 -0.007\n",
      "playerIds Var    0.001    0.012                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "=========================================================\n",
      "Model:              MixedLM  Dependent Variable:  weak   \n",
      "No. Observations:   159      Method:              REML   \n",
      "No. Groups:         53       Scale:               0.0244 \n",
      "Min. group size:    3        Log-Likelihood:      54.5720\n",
      "Max. group size:    3        Converged:           Yes    \n",
      "Mean group size:    3.0                                  \n",
      "---------------------------------------------------------\n",
      "                Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
      "---------------------------------------------------------\n",
      "Intercept       1.208    0.053 22.855 0.000  1.104  1.312\n",
      "task_complexity 0.009    0.015  0.587 0.557 -0.021  0.039\n",
      "playerCount     0.001    0.009  0.097 0.923 -0.017  0.019\n",
      "playerIds Var   0.002    0.016                           \n",
      "=========================================================\n",
      "\n",
      "****Results for Task: Allocating Resources ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  strong   \n",
      "No. Observations:  162      Method:              REML     \n",
      "No. Groups:        54       Scale:               0.1583   \n",
      "Min. group size:   3        Log-Likelihood:      -103.2442\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.850    0.154  5.511 0.000  0.548  1.152\n",
      "task_complexity  0.039    0.038  1.030 0.303 -0.036  0.114\n",
      "playerCount     -0.057    0.029 -1.989 0.047 -0.113 -0.001\n",
      "playerIds Var    0.046    0.059                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak     \n",
      "No. Observations:  162      Method:              REML     \n",
      "No. Groups:        54       Scale:               0.5338   \n",
      "Min. group size:   3        Log-Likelihood:      -199.9889\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.483    0.284  5.225 0.000  0.926  2.039\n",
      "task_complexity -0.007    0.070 -0.095 0.924 -0.144  0.131\n",
      "playerCount     -0.057    0.053 -1.089 0.276 -0.160  0.046\n",
      "playerIds Var    0.157    0.110                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Divergent Association ****\n",
      "===Strong Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:               MixedLM  Dependent Variable:  strong \n",
      "No. Observations:    149      Method:              REML   \n",
      "No. Groups:          50       Scale:               0.0138 \n",
      "Min. group size:     2        Log-Likelihood:      96.0721\n",
      "Max. group size:     3        Converged:           Yes    \n",
      "Mean group size:     3.0                                  \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        0.945    0.039 24.099 0.000  0.868  1.022\n",
      "task_complexity  0.035    0.012  2.941 0.003  0.012  0.058\n",
      "playerCount     -0.008    0.007 -1.274 0.203 -0.021  0.005\n",
      "playerIds Var    0.000    0.010                           \n",
      "==========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:               MixedLM  Dependent Variable:  weak   \n",
      "No. Observations:    149      Method:              REML   \n",
      "No. Groups:          50       Scale:               0.0213 \n",
      "Min. group size:     2        Log-Likelihood:      64.2137\n",
      "Max. group size:     3        Converged:           Yes    \n",
      "Mean group size:     3.0                                  \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.133    0.049 23.153 0.000  1.037  1.229\n",
      "task_complexity  0.024    0.015  1.650 0.099 -0.005  0.053\n",
      "playerCount     -0.000    0.008 -0.057 0.955 -0.017  0.016\n",
      "playerIds Var    0.001    0.013                           \n",
      "==========================================================\n",
      "\n",
      "****Results for Task: Wolf Goat Cabbage ****\n",
      "===Strong Group Advantage===\n",
      "         Mixed Linear Model Regression Results\n",
      "========================================================\n",
      "Model:              MixedLM Dependent Variable: strong  \n",
      "No. Observations:   192     Method:             REML    \n",
      "No. Groups:         64      Scale:              0.1087  \n",
      "Min. group size:    3       Log-Likelihood:     -90.2165\n",
      "Max. group size:    3       Converged:          Yes     \n",
      "Mean group size:    3.0                                 \n",
      "--------------------------------------------------------\n",
      "                Coef. Std.Err.   z   P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------\n",
      "Intercept       0.671    0.122 5.516 0.000  0.433  0.910\n",
      "task_complexity 0.051    0.029 1.740 0.082 -0.006  0.108\n",
      "playerCount     0.031    0.023 1.321 0.186 -0.015  0.077\n",
      "playerIds Var   0.041    0.052                          \n",
      "========================================================\n",
      "\n",
      "===Weak Group Advantage===\n",
      "          Mixed Linear Model Regression Results\n",
      "==========================================================\n",
      "Model:             MixedLM  Dependent Variable:  weak     \n",
      "No. Observations:  192      Method:              REML     \n",
      "No. Groups:        64       Scale:               0.4958   \n",
      "Min. group size:   3        Log-Likelihood:      -226.5738\n",
      "Max. group size:   3        Converged:           Yes      \n",
      "Mean group size:   3.0                                    \n",
      "----------------------------------------------------------\n",
      "                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "----------------------------------------------------------\n",
      "Intercept        1.461    0.239  6.121 0.000  0.993  1.929\n",
      "task_complexity -0.183    0.062 -2.940 0.003 -0.305 -0.061\n",
      "playerCount      0.148    0.045  3.324 0.001  0.061  0.236\n",
      "playerIds Var    0.117    0.088                           \n",
      "==========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in df_observation_level_data[\"task\"].unique():\n",
    "\n",
    "    print(\"****Results for Task: \" +  task + \" ****\")\n",
    "\n",
    "    task_data = df_observation_level_data[df_observation_level_data[\"task\"] == task]\n",
    "    \n",
    "    # turn the categories [\"Low\", \"Medium\", and \"High\"] into an ordinal variable in the df task_data\n",
    "    task_data['task_complexity'] = 1 * task_data['Low'] + 2 * task_data['Medium'] + 3 * task_data['High']\n",
    "\n",
    "    # Fit a regression of Group Advantage ~ Task Complexity + Group Size with a random effect for group ID\n",
    "    strong_model = sm.MixedLM.from_formula(\"strong ~ task_complexity + playerCount\", groups=\"playerIds\", data=task_data)\n",
    "    strong_result = strong_model.fit()\n",
    "    print(\"===Strong Group Advantage===\")\n",
    "    print(strong_result.summary())\n",
    "\n",
    "    weak_model = sm.MixedLM.from_formula(\"weak ~ task_complexity + playerCount\", groups=\"playerIds\", data=task_data)\n",
    "    weak_result = weak_model.fit()\n",
    "    print(\"===Weak Group Advantage===\")\n",
    "    print(weak_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure for Storing the Final Models & Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = {\n",
    "            \"OLS\": {\n",
    "                \"Wave 1a\": {\"strong\": None, \"weak\": None},\n",
    "                \"Wave 1\": {\"strong\": None, \"weak\": None},\n",
    "                \"Wave 2\": {\"strong\": None, \"weak\": None}\n",
    "            },\n",
    "            \"E-Net\": {\n",
    "                \"Wave 1a\": {\"strong\": None, \"weak\": None},\n",
    "                \"Wave 1\": {\"strong\": None, \"weak\": None},\n",
    "                \"Wave 2\": {\"strong\": None, \"weak\": None}\n",
    "            },\n",
    "            \"NN\": {\n",
    "                \"Wave 1a\": {\"strong\": None, \"weak\": None},\n",
    "                \"Wave 1\": {\"strong\": None, \"weak\": None},\n",
    "                \"Wave 2\": {\"strong\": None, \"weak\": None}\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 (types of predictors) x 3 (models) x 3 (waves for training data) = 18 models\n",
    "try:\n",
    "    # read the models and results from the previous save\n",
    "    with open('../outputs/models.pkl', 'rb') as f:\n",
    "        MODELS = pickle.load(f)\n",
    "    with open('../outputs/model_r2_results.pkl', 'rb') as f:\n",
    "        MODEL_R2_RESULTS = pickle.load(f)\n",
    "    with open('../outputs/model_rmse_results.pkl', 'rb') as f:\n",
    "        MODEL_RMSE_RESULTS = pickle.load(f)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # if the file is not found, we will create the MODELS and MODEL_R2_RESULTS dictionaries\n",
    "    MODELS = {\n",
    "        \"Task Space\": copy.deepcopy(base_model),\n",
    "        \"McGrath Categorical\": copy.deepcopy(base_model),\n",
    "        \"McGrath Subspace\": copy.deepcopy(base_model),\n",
    "        \"Steiner Subspace\": copy.deepcopy(base_model),\n",
    "        \"Laughlin Subspace\": copy.deepcopy(base_model)\n",
    "    }\n",
    "\n",
    "    # create a dictionary with the sake keys as MODELS to story R2 results\n",
    "    MODEL_R2_RESULTS = copy.deepcopy(MODELS)\n",
    "\n",
    "    # create a dictionary with the sake keys as MODELS to story RMSE results\n",
    "    MODEL_RMSE_RESULTS = copy.deepcopy(MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save MODELS and MODEL_R2_RESULTS\n",
    "def save_current_model_and_results_version(MODELS, MODEL_R2_RESULTS, MODEL_RMSE_RESULTS):\n",
    "    with open('../outputs/models.pkl', 'wb') as f:\n",
    "        pickle.dump(MODELS, f)\n",
    "    with open('../outputs/model_r2_results.pkl', 'wb') as f:\n",
    "        pickle.dump(MODEL_R2_RESULTS, f)\n",
    "    with open('../outputs/model_rmse_results.pkl', 'wb') as f:\n",
    "        pickle.dump(MODEL_RMSE_RESULTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a \"Wave 1a that holds out half of Wave 1\"\n",
    "wave1_tasks = df_condition_level_data[df_condition_level_data['wave']==1]['task'].unique()\n",
    "\n",
    "# Set a random seed for reproducibility, then select half the wave 1 tasks\n",
    "random.seed(19104)\n",
    "wave1a_tasks = random.sample(list(wave1_tasks), len(wave1_tasks) // 2)\n",
    "wave1b_tasks = [task for task in wave1_tasks if task not in wave1a_tasks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out 15 tasks\n",
    "wave1a_df_train = df_condition_level_data[df_condition_level_data[\"task\"].isin(wave1a_tasks)] ## train on this\n",
    "wave1a_df_test = df_condition_level_data[~df_condition_level_data[\"task\"].isin(wave1a_tasks)] ## test on everything else\n",
    "\n",
    "# Hold out 10 tasks\n",
    "wave1_df_train = df_condition_level_data[df_condition_level_data[\"wave\"] == 1] ## train on this\n",
    "wave1_df_test = df_condition_level_data[df_condition_level_data[\"wave\"] > 1] ## test on everything else\n",
    "\n",
    "# Hold out 5 tasks\n",
    "wave12_df_train = df_condition_level_data[df_condition_level_data[\"wave\"] <= 2] ## then train on this\n",
    "wave12_df_test = df_condition_level_data[df_condition_level_data[\"wave\"] == 3] ## test on everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datastructure for the training and testing data\n",
    "TRAIN_TEST_DATA = {\n",
    "    \"Wave 1a\": {\n",
    "        \"train\": wave1a_df_train,\n",
    "        \"test\": wave1a_df_test\n",
    "    },\n",
    "    \"Wave 1\": {\n",
    "        \"train\": wave1_df_train,\n",
    "        \"test\": wave1_df_test\n",
    "    },\n",
    "    \"Wave 2\": {\n",
    "        \"train\": wave12_df_train,\t\n",
    "        \"test\": wave12_df_test\n",
    "    }\n",
    "}\n",
    "\n",
    "# save TRAIN_TEST_DATA as a pickle file\n",
    "with open('../outputs/train_test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(TRAIN_TEST_DATA, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of IV's\n",
    "basic_IVs = [col for col in df_condition_level_data.columns if \n",
    "    \"categorical\" not in col and \"task\" not in col and \"strong\" not in col and \"weak\" not in col and \"wave\" not in col]\n",
    "\n",
    "mcgrath_continuous = [col for col in basic_IVs if \"Type\" in col] + [\"Conceptual-Behavioral\"]\n",
    "\n",
    "steiner_continuous = [\"Divisible-Unitary\", \"Maximizing\", \"Optimizing\"]\n",
    "\n",
    "laughlin_continuous = [\"Decision Verifiability\", \"Shared Knowledge\", \"Within-System Solution\", \"Answer Recognizability\", \"Time Solvability\", \"Intellective-Judgmental\", \"Eureka Question\"]\n",
    "\n",
    "categorical_IVs = [col for col in df_condition_level_data.columns if \"categorical\" in col] + [\"playerCount\", \"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "# save the lists of IVs\n",
    "with open('../outputs/iv_lists.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        \"basic_IVs\": basic_IVs,\n",
    "        \"mcgrath_continuous\": mcgrath_continuous,\n",
    "        \"steiner_continuous\": steiner_continuous,\n",
    "        \"laughlin_continuous\": laughlin_continuous,\n",
    "        \"categorical_IVs\": categorical_IVs\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to train on one wave and test on another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate RMSE between true and predicted values.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "# function for getting RMSE from a trained model (OLS)\n",
    "def get_rmse_ols(model_ols, X_test, y_true, ivs):\n",
    "    X_test_ols = sm.add_constant(X_test[ivs].copy(), has_constant='add')\n",
    "    y_pred_ols = model_ols.predict(X_test_ols)\n",
    "    rmse_ols = get_rmse(y_true, y_pred_ols)\n",
    "\n",
    "    return rmse_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wave_a(wave_a_data, dv_type, ivs):\n",
    "    assert dv_type in [\"strong\", \"weak\"]\n",
    "    X = wave_a_data[ivs]\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    y = wave_a_data[dv_type]\n",
    "    return sm.OLS(y, X).fit()\n",
    "\n",
    "def custom_r2(y_pred, y_actual, wave_a_data, wave_b_data, dv_type):\n",
    "    # Compute R^2 on the test set, using the training set as a baseline\n",
    "    naive_prediction_errs = []\n",
    "    for i, row in wave_b_data.iterrows():\n",
    "        \n",
    "        # get all instances of groups of the same size performing \n",
    "        # all the tasks in the training set at the same complexity level.\n",
    "        playerCount = row[\"playerCount\"]\n",
    "        wave_a_subset = wave_a_data[(wave_a_data[\"playerCount\"] == playerCount) & \n",
    "                                    (wave_a_data[\"Low\"] == row[\"Low\"]) & \n",
    "                                    (wave_a_data[\"Medium\"] == row[\"Medium\"]) &\n",
    "                                    (wave_a_data[\"High\"] == row[\"High\"])]\n",
    "        y_training = np.mean(wave_a_subset[dv_type])\n",
    "        # predict the value of the DV (in wave_b) using the mean of the training data (from wave_a)\n",
    "        y_actual_i = row[dv_type]\n",
    "        fold_err = (y_actual_i - y_training)**2\n",
    "        naive_prediction_errs.append(fold_err)\n",
    "\n",
    "    r2 = 1 - np.sum((y_pred - y_actual)**2) / np.sum(naive_prediction_errs)\n",
    "    \n",
    "    return r2\n",
    "\n",
    "def test_wave_b(wave_a_data, wave_b_data, model, dv_type, ivs):\n",
    "    assert dv_type in [\"strong\", \"weak\"]\n",
    "    \n",
    "    X = wave_b_data[ivs]\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    y_actual = wave_b_data[dv_type]\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = custom_r2(y_pred, y_actual, wave_a_data, wave_b_data, dv_type)\n",
    "    \n",
    "    return r2, y_actual, y_pred\n",
    "\n",
    "def plot_results(y_actual, y_pred, y_train, r2, title=\"Model Results (Figure 2)\"):\n",
    "    min_val = min(0, 0) # fix at 0,0\n",
    "    larger_max_val = max(y_actual.max(), y_pred.max())\n",
    "    round_max_val = round(larger_max_val, 0)\n",
    "    max_val = max(round_max_val, round_max_val) # the larger max value (between the predicted and the actual)\n",
    "    \n",
    "    plt.scatter(y_actual, y_pred)\n",
    "    plt.axhline(y_train.mean(), color='r', linestyle='-')\n",
    "\n",
    "    # plot y=x line\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=1)\n",
    "    plt.text(0.1, 0.9, f\"$R^2$ = {r2:.2f}\", transform=plt.gca().transAxes, fontsize=20)\n",
    "\n",
    "    plt.xlim(min_val, max_val) # gotta make sure the lims are the same\n",
    "    plt.ylim(min_val, max_val)\n",
    "    plt.xlabel(\"Observed\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def train_wave_a_test_wave_b(wave_a_data, wave_b_data, dv_type, ivs, title, plot = False):\n",
    "    model = train_wave_a(wave_a_data, dv_type, ivs)\n",
    "    r2, y, y_pred = test_wave_b(wave_a_data, wave_b_data, model, dv_type, ivs)\n",
    "    if plot:\n",
    "        # plot the results; defaults to false because it gets a little overwhelming :)\n",
    "        plot_results(y, y_pred, wave_a_data[dv_type], r2, title)\n",
    "    return model, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wave in TRAIN_TEST_DATA.keys():\n",
    "    for model_type in MODELS.keys():\n",
    "        for dv_type in [\"strong\", \"weak\"]:\n",
    "            # if the model for this wave and dv_type is not trained yet, train it\n",
    "            if not MODELS[model_type][\"OLS\"][wave][dv_type] or not MODEL_R2_RESULTS[model_type][\"OLS\"][wave][dv_type]:\n",
    "\n",
    "                # get the training and testing data\n",
    "                wave_a_data = TRAIN_TEST_DATA[wave][\"train\"]\n",
    "                wave_b_data = TRAIN_TEST_DATA[wave][\"test\"]\n",
    "\n",
    "                if model_type == \"Task Space\":\n",
    "                    ivs = basic_IVs\n",
    "                elif model_type == \"McGrath Categorical\":\n",
    "                    ivs = categorical_IVs\n",
    "                elif model_type == \"McGrath Subspace\":\n",
    "                    ivs = mcgrath_continuous\n",
    "                elif model_type == \"Steiner Subspace\":\n",
    "                    ivs = steiner_continuous\n",
    "                elif model_type == \"Laughlin Subspace\":\n",
    "                    ivs = laughlin_continuous\n",
    "                else:\n",
    "                    raise ValueError(\"Unknown model type: {}\".format(model_type))\n",
    "\n",
    "                # train the model and test it\n",
    "                model, r2 = train_wave_a_test_wave_b(wave_a_data, wave_b_data, dv_type, ivs, \n",
    "                                                    f\"{model_type} {dv_type} {wave}\", plot=False)\n",
    "                \n",
    "                rmse = get_rmse_ols(model, wave_b_data, wave_b_data[dv_type], ivs)\n",
    "                \n",
    "                # store the results\n",
    "                MODELS[model_type][\"OLS\"][wave][dv_type] = model\n",
    "                MODEL_R2_RESULTS[model_type][\"OLS\"][wave][dv_type] = r2\n",
    "                MODEL_RMSE_RESULTS[model_type][\"OLS\"][wave][dv_type] = rmse\n",
    "                save_current_model_and_results_version(MODELS, MODEL_R2_RESULTS, MODEL_RMSE_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interactions(X):\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    return poly.fit_transform(X)\n",
    "\n",
    "def get_rmse_for_enet(model_enet, X_test, y_true, ivs):\n",
    "    X_test_enet = add_interactions(X_test[ivs].copy())\n",
    "    y_pred_enet = model_enet.predict(X_test_enet)\n",
    "    rmse_enet = get_rmse(y_true, y_pred_enet)\n",
    "\n",
    "    return rmse_enet\n",
    "\n",
    "def train_wave_a_enet(wave_a_data, dv_type, ivs, random_state=19104):\n",
    "    assert dv_type in [\"strong\", \"weak\"]\n",
    "    X = wave_a_data[ivs]\n",
    "    X_interactions = add_interactions(X)\n",
    "    y = wave_a_data[dv_type]\n",
    "    \n",
    "    # Define a range of values for alpha and l1_ratio\n",
    "    alphas = np.logspace(-4, 1, 50)\n",
    "    l1_ratio = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "\n",
    "    # Initialize and fit ElasticNetCV\n",
    "    elastic_net_cv = ElasticNetCV(cv=5, alphas=alphas, l1_ratio=l1_ratio, random_state=random_state)\n",
    "    elastic_net_cv.fit(X_interactions, y)\n",
    "    \n",
    "    # Re-fit the model on the full training dataset using the best hyperparameters\n",
    "    elastic_net = ElasticNet(alpha=elastic_net_cv.alpha_, l1_ratio=elastic_net_cv.l1_ratio_)\n",
    "    elastic_net.fit(X_interactions, y)\n",
    "    \n",
    "    return elastic_net\n",
    "\n",
    "def test_wave_b_enet(wave_a_data, wave_b_data, model, dv_type, ivs):\n",
    "    assert dv_type in [\"strong\", \"weak\"]\n",
    "    \n",
    "    X = wave_b_data[ivs]\n",
    "    X_interactions = add_interactions(X)\n",
    "    y_actual = wave_b_data[dv_type]\n",
    "    y_pred = model.predict(X_interactions)\n",
    "    \n",
    "    r2 = custom_r2(y_pred, y_actual, wave_a_data, wave_b_data, dv_type)\n",
    "    \n",
    "    return r2, y_actual, y_pred\n",
    "\n",
    "def train_wave_a_test_wave_b_enet(wave_a_data, wave_b_data, dv_type, ivs, title, plot=False):\n",
    "    model = train_wave_a_enet(wave_a_data, dv_type, ivs)\n",
    "    r2, y_actual, y_pred = test_wave_b_enet(wave_a_data, wave_b_data, model, dv_type, ivs)\n",
    "    if plot:\n",
    "        plot_results(y_actual, y_pred, wave_a_data[dv_type], r2, title)\n",
    "    return model, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our ENet Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waves: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 50131.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for wave in tqdm(TRAIN_TEST_DATA.keys(), desc=\"Waves\"):\n",
    "    for model_type in MODELS.keys():\n",
    "        for dv_type in [\"strong\", \"weak\"]:\n",
    "            \n",
    "            if not MODELS[model_type][\"E-Net\"][wave][dv_type] or not MODEL_R2_RESULTS[model_type][\"E-Net\"][wave][dv_type]:\n",
    "                # Get the training and testing data\n",
    "                wave_a_data = TRAIN_TEST_DATA[wave][\"train\"]\n",
    "                wave_b_data = TRAIN_TEST_DATA[wave][\"test\"]\n",
    "\n",
    "                if model_type == \"Task Space\":\n",
    "                    ivs = basic_IVs\n",
    "                elif model_type == \"McGrath Categorical\":\n",
    "                    ivs = categorical_IVs\n",
    "                elif model_type == \"McGrath Subspace\":\n",
    "                    ivs = mcgrath_continuous\n",
    "                elif model_type == \"Steiner Subspace\":\n",
    "                    ivs = steiner_continuous\n",
    "                elif model_type == \"Laughlin Subspace\":\n",
    "                    ivs = laughlin_continuous\n",
    "                else:\n",
    "                    raise ValueError(\"Unknown model type: {}\".format(model_type))\n",
    "\n",
    "                # Train the model and test it\n",
    "                model, r2 = train_wave_a_test_wave_b_enet(wave_a_data, wave_b_data, dv_type, ivs, \n",
    "                                                        f\"{model_type} {dv_type} {wave}\", plot=False)\n",
    "                rmse = get_rmse_for_enet(model, wave_b_data, wave_b_data[dv_type], ivs)\n",
    "                \n",
    "                # Store the results\n",
    "                MODELS[model_type][\"E-Net\"][wave][dv_type] = model\n",
    "                MODEL_R2_RESULTS[model_type][\"E-Net\"][wave][dv_type] = r2\n",
    "                MODEL_RMSE_RESULTS[model_type][\"E-Net\"][wave][dv_type] = rmse\n",
    "                save_current_model_and_results_version(MODELS, MODEL_R2_RESULTS, MODEL_RMSE_RESULTS)\n",
    "\n",
    "                # Optional: Print progress information\n",
    "                print(f\"Completed: {model_type} - {dv_type} - {wave}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(trial: Trial, input_shape):\n",
    "#     # hyperparameters from Mark's comment\n",
    "#     learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-1)\n",
    "#     n_units = trial.suggest_int(\"n_units\", 32, 512)\n",
    "#     n_layers = trial.suggest_categorical(\"n_layers\", [1, 2, 3, 4, 5])\n",
    "#     batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "#     dropout_rate = trial.suggest_uniform(\"dropout_rate\", 0.0, 0.3)\n",
    "#     activation = trial.suggest_categorical(\"activation\", ['relu'])\n",
    "\n",
    "#     # Build model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(n_units, activation=activation, input_shape=input_shape))\n",
    "    \n",
    "#     for _ in range(1, n_layers):\n",
    "#         model.add(Dense(n_units, activation=activation))\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#                    loss='mean_squared_error')\n",
    "    \n",
    "#     return model, batch_size\n",
    "\n",
    "# def leave_one_task_out(df, model_func, iv, dv):\n",
    "#     # assert that dv is one of 'strong' or 'weak'\n",
    "#     assert dv in [\"strong\", \"weak\"]\n",
    "\n",
    "#     tasks = df[\"task\"].unique()\n",
    "#     total_left_out_loss = 0\n",
    "\n",
    "#     for task in tasks:\n",
    "#         train_data = df[df[\"task\"] != task]\n",
    "#         test_data = df[df[\"task\"] == task]\n",
    "        \n",
    "#         X_train, y_train = train_data[iv], train_data[dv]\n",
    "#         X_test, y_test = test_data[iv], test_data[dv]\n",
    "\n",
    "#         input_shape = (X_train.shape[1],)\n",
    "#         model, batch_size = model_func(input_shape)\n",
    "        \n",
    "#         model.fit(X_train, y_train, batch_size=batch_size, epochs=100, verbose=0)\n",
    "#         loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "#         total_left_out_loss += loss\n",
    "\n",
    "#     return total_left_out_loss\n",
    "\n",
    "# \"\"\"Define objectives\"\"\"\n",
    "# def objective(trial, wave_data, iv, dv):\n",
    "#     def model_func(input_shape):\n",
    "#         return create_model(trial, input_shape)\n",
    "#     total_loss = leave_one_task_out(wave_data, model_func, iv=iv, dv=dv)\n",
    "#     return total_loss\n",
    "\n",
    "# def optimize_and_save(study_name, wave_data, iv, dv):\n",
    "#     try:\n",
    "#         # Load the hyperparameters from the .pkl file\n",
    "#         with open(f\"../outputs/best_param_pkls/best_params_{study_name}.pkl\", \"rb\") as f:\n",
    "#             best_params = pickle.load(f)\n",
    "#     except FileNotFoundError:\n",
    "#         study = create_study(direction=\"minimize\")\n",
    "#         study.optimize(lambda trial: objective(trial, wave_data, iv, dv), n_trials=100)\n",
    "\n",
    "#         best_trial = study.best_trial\n",
    "#         best_params = best_trial.params\n",
    "#         # Save the hyperparameters to a .pkl file\n",
    "#         with open(f\"../outputs/best_param_pkls/best_params_{study_name}.pkl\", \"wb\") as f:\n",
    "#             pickle.dump(best_params, f)\n",
    "\n",
    "#     return best_params\n",
    "\n",
    "# def set_random_seeds(seed_value=19104):\n",
    "#     random.seed(seed_value)\n",
    "#     np.random.seed(seed_value)\n",
    "#     tf.random.set_seed(seed_value)\n",
    "\n",
    "# def create_best_model(input_shape, best_params):    \n",
    "#     learning_rate = best_params['learning_rate']\n",
    "#     n_units = best_params['n_units']\n",
    "#     n_layers = best_params['n_layers']\n",
    "#     batch_size = best_params['batch_size']\n",
    "#     dropout_rate = best_params['dropout_rate']\n",
    "#     activation = best_params['activation']\n",
    "    \n",
    "#     # Build model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(n_units, activation=activation, input_shape=input_shape))\n",
    "    \n",
    "#     for _ in range(1, n_layers):\n",
    "#         model.add(Dense(n_units, activation=activation))\n",
    "#         model.add(Dropout(dropout_rate))\n",
    "    \n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#                   loss='mean_squared_error')\n",
    "    \n",
    "#     return model, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_wave_a_nn(wave_a_data, ivs, dv_type):\n",
    "#     assert dv_type in [\"strong\", \"weak\"]\n",
    "\n",
    "#     # Random seed for reproducibility\n",
    "#     set_random_seeds()\n",
    "\n",
    "#     # Objective function for Optuna\n",
    "#     def objective(trial):\n",
    "#         return leave_one_task_out(wave_a_data, lambda shape: create_model(trial, shape), ivs, dv_type)\n",
    "\n",
    "#     # Hyperparameter optimization\n",
    "#     study = create_study(direction=\"minimize\")\n",
    "#     study.optimize(objective, n_trials=100)\n",
    "\n",
    "#     best_params = study.best_trial.params\n",
    "\n",
    "#     input_shape = (wave_a_data[ivs].shape[1],)\n",
    "#     model, batch_size = create_best_model(input_shape, best_params)\n",
    "    \n",
    "#     X_train = wave_a_data[ivs]\n",
    "#     y_train = wave_a_data[dv_type]\n",
    "\n",
    "#     model.fit(X_train, y_train, batch_size=batch_size, epochs=100, verbose=0)\n",
    "\n",
    "#     print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "# def test_wave_b_nn(wave_a_data, wave_b_data, model, ivs, dv_type):\n",
    "#     X_new = wave_b_data[ivs]\n",
    "#     y_actual = wave_b_data[dv_type]\n",
    "\n",
    "#     # Ensure consistent shape\n",
    "#     if len(X_new.shape) == 1:\n",
    "#         X_new = X_new.reshape(-1, 1)\n",
    "\n",
    "#     y_pred = model.predict(X_new).flatten()\n",
    "\n",
    "#     r2 = custom_r2(y_pred, y_actual, wave_a_data, wave_b_data, dv_type)\n",
    "\n",
    "#     return r2, y_actual, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commenting out because these take too long...\n",
    "\n",
    "# for wave in tqdm(TRAIN_TEST_DATA.keys(), desc=\"Waves\"):\n",
    "# \tfor model_type in tqdm(MODELS.keys(), desc=\"Model Types\", leave=False):\n",
    "# \t\tfor dv_type in tqdm([\"strong\", \"weak\"], desc=\"DV Types\", leave=False):\n",
    "\n",
    "# \t\t\tif not MODELS[model_type][\"NN\"][wave][dv_type] or not MODEL_R2_RESULTS[model_type][\"NN\"][wave][dv_type]:\n",
    "# \t\t\t\twave_a_data = TRAIN_TEST_DATA[wave][\"train\"]\n",
    "# \t\t\t\twave_b_data = TRAIN_TEST_DATA[wave][\"test\"]\n",
    "\n",
    "# \t\t\t\tif model_type == \"Task Space\":\n",
    "# \t\t\t\t\tivs = basic_IVs\n",
    "# \t\t\t\telif model_type == \"McGrath Categorical\":\n",
    "# \t\t\t\t\tivs = categorical_IVs\n",
    "# \t\t\t\telif model_type == \"McGrath Subspace\":\n",
    "# \t\t\t\t\tivs = mcgrath_continuous\n",
    "# \t\t\t\telif model_type == \"Steiner Subspace\":\n",
    "# \t\t\t\t\tivs = steiner_continuous\n",
    "# \t\t\t\telif model_type == \"Laughlin Subspace\":\n",
    "# \t\t\t\t\tivs = laughlin_continuous\n",
    "# \t\t\t\telse:\n",
    "# \t\t\t\t\traise ValueError(\"Unknown model type: {}\".format(model_type))\n",
    "\n",
    "# \t\t\t\tmodel = train_wave_a_nn(wave_a_data, ivs, dv_type)\n",
    "# \t\t\t\tr2, y_actual, y_pred = test_wave_b_nn(wave_a_data, wave_b_data, model, ivs, dv_type)\n",
    "# \t\t\t\t\n",
    "# TODO: CREATE AN RMSE FUNCTION! rmse = get_rmse_nn(y_actual, y_pred)       \n",
    "\n",
    "# \t\t\t\tMODELS[model_type][\"NN\"][wave][dv_type] = model\n",
    "# \t\t\t\tMODEL_R2_RESULTS[model_type][\"NN\"][wave][dv_type] = r2\n",
    "# \t\t\t\tsave_current_model_and_results_version(MODELS, MODEL_R2_RESULTS, MODEL_RMSE_RESULTS)\n",
    "\n",
    "# \t\t\t\tprint(f\"Completed: {model_type} - {dv_type} - {wave}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Results for Strong Group Advantage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>E-Net</th>\n",
       "      <th>OLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV Type</th>\n",
       "      <th>Training Wave</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Laughlin Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Categorical</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Steiner Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Task Space</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                              E-Net   OLS\n",
       "IV Type             Training Wave             \n",
       "Laughlin Subspace   Wave 1a         0.27  0.30\n",
       "                    Wave 1          0.16 -0.37\n",
       "                    Wave 2          0.28  0.14\n",
       "McGrath Categorical Wave 1a         0.18  0.16\n",
       "                    Wave 1         -0.31 -0.28\n",
       "                    Wave 2         -0.02 -0.03\n",
       "McGrath Subspace    Wave 1a         0.19  0.35\n",
       "                    Wave 1          0.17  0.25\n",
       "                    Wave 2          0.31  0.23\n",
       "Steiner Subspace    Wave 1a         0.01 -0.92\n",
       "                    Wave 1          0.01 -0.08\n",
       "                    Wave 2          0.20  0.12\n",
       "Task Space          Wave 1a         0.23  0.45\n",
       "                    Wave 1          0.40  0.43\n",
       "                    Wave 2          0.43  0.33"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Results for Weak Group Advantage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>E-Net</th>\n",
       "      <th>OLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV Type</th>\n",
       "      <th>Training Wave</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Laughlin Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Categorical</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Steiner Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Task Space</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                              E-Net   OLS\n",
       "IV Type             Training Wave             \n",
       "Laughlin Subspace   Wave 1a        -0.03 -0.05\n",
       "                    Wave 1          0.02 -1.11\n",
       "                    Wave 2         -0.02 -0.23\n",
       "McGrath Categorical Wave 1a         0.00 -0.03\n",
       "                    Wave 1          0.02 -0.05\n",
       "                    Wave 2         -0.03  0.06\n",
       "McGrath Subspace    Wave 1a         0.00  0.24\n",
       "                    Wave 1         -0.02 -0.60\n",
       "                    Wave 2         -0.17  0.03\n",
       "Steiner Subspace    Wave 1a         0.27  0.36\n",
       "                    Wave 1          0.31  0.07\n",
       "                    Wave 2          0.13  0.13\n",
       "Task Space          Wave 1a         0.00  0.32\n",
       "                    Wave 1          0.02  0.48\n",
       "                    Wave 2          0.40  0.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Results for Strong Group Advantage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>E-Net</th>\n",
       "      <th>OLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV Type</th>\n",
       "      <th>Training Wave</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Laughlin Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Categorical</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Steiner Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Task Space</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                              E-Net   OLS\n",
       "IV Type             Training Wave             \n",
       "Laughlin Subspace   Wave 1a         0.30  0.29\n",
       "                    Wave 1          0.30  0.39\n",
       "                    Wave 2          0.31  0.34\n",
       "McGrath Categorical Wave 1a         0.31  0.32\n",
       "                    Wave 1          0.38  0.37\n",
       "                    Wave 2          0.37  0.38\n",
       "McGrath Subspace    Wave 1a         0.31  0.28\n",
       "                    Wave 1          0.30  0.29\n",
       "                    Wave 2          0.31  0.33\n",
       "Steiner Subspace    Wave 1a         0.34  0.48\n",
       "                    Wave 1          0.33  0.34\n",
       "                    Wave 2          0.33  0.35\n",
       "Task Space          Wave 1a         0.30  0.26\n",
       "                    Wave 1          0.26  0.25\n",
       "                    Wave 2          0.28  0.30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE^2 Results for Weak Group Advantage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>E-Net</th>\n",
       "      <th>OLS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IV Type</th>\n",
       "      <th>Training Wave</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Laughlin Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Categorical</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">McGrath Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Steiner Subspace</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Task Space</th>\n",
       "      <th>Wave 1a</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 1</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wave 2</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                              E-Net   OLS\n",
       "IV Type             Training Wave             \n",
       "Laughlin Subspace   Wave 1a         0.89  0.90\n",
       "                    Wave 1          0.74  1.09\n",
       "                    Wave 2          0.76  0.84\n",
       "McGrath Categorical Wave 1a         0.87  0.89\n",
       "                    Wave 1          0.74  0.77\n",
       "                    Wave 2          0.77  0.73\n",
       "McGrath Subspace    Wave 1a         0.87  0.76\n",
       "                    Wave 1          0.76  0.95\n",
       "                    Wave 2          0.81  0.74\n",
       "Steiner Subspace    Wave 1a         0.75  0.70\n",
       "                    Wave 1          0.62  0.72\n",
       "                    Wave 2          0.70  0.70\n",
       "Task Space          Wave 1a         0.87  0.72\n",
       "                    Wave 1          0.74  0.54\n",
       "                    Wave 2          0.58  0.61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_r2_dataframe(results_dict, dv_type):\n",
    "    data = []\n",
    "\n",
    "    for iv_type, models in results_dict.items():\n",
    "        for model_type, waves in models.items():\n",
    "            for wave, dv_values in waves.items():\n",
    "                if dv_values[dv_type] is not None:\n",
    "                    data.append({\n",
    "                        'IV Type': iv_type,\n",
    "                        'Training Wave': wave,\n",
    "                        'Model': model_type,\n",
    "                        'R^2': dv_values[dv_type]\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['R^2'] = df['R^2'].round(2)\n",
    "\n",
    "    # Order the 'Training Wave' column\n",
    "    wave_order = ['Wave 1a', 'Wave 1', 'Wave 2']\n",
    "    df['Training Wave'] = pd.Categorical(df['Training Wave'], categories=wave_order, ordered=True)\n",
    "\n",
    "    df_pivot = df.pivot_table(values='R^2', index=['IV Type', 'Training Wave'], columns='Model')\n",
    "    \n",
    "    return df_pivot\n",
    "\n",
    "print(\"R^2 Results for Strong Group Advantage:\")\n",
    "display(create_r2_dataframe(MODEL_R2_RESULTS, \"strong\"))\n",
    "print(\"R^2 Results for Weak Group Advantage:\")\n",
    "display(create_r2_dataframe(MODEL_R2_RESULTS, \"weak\"))\n",
    "\n",
    "print(\"RMSE Results for Strong Group Advantage:\")\n",
    "display(create_r2_dataframe(MODEL_RMSE_RESULTS, \"strong\"))\n",
    "print(\"RMSE^2 Results for Weak Group Advantage:\")\n",
    "display(create_r2_dataframe(MODEL_RMSE_RESULTS, \"weak\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boostrapped Robustness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to read in BOOTSTRAP_R2_RESULTS if it exists, otherwise create it\n",
    "bootstrap_r2_pkl_filename = '../outputs/bootstrap_r2_results.pkl'\n",
    "bootstrap_model_pkl_filename = '../outputs/bootstrap_models.pkl'\n",
    "bootstrap_rmse_pkl_filename = '../outputs/bootstrap_rmse_results.pkl'\n",
    "\n",
    "try:\n",
    "    with open(bootstrap_r2_pkl_filename, 'rb') as f:\n",
    "        BOOTSTRAP_R2_RESULTS = pickle.load(f)\n",
    "    with open(bootstrap_model_pkl_filename, 'rb') as f:\n",
    "        BOOTSTRAP_MODELS = pickle.load(f)\n",
    "    with open(bootstrap_rmse_pkl_filename, 'rb') as f:\n",
    "        BOOTSTRAP_RMSE_RESULTS = pickle.load(f)\n",
    "except FileNotFoundError:\n",
    "    base_results_by_dv = {\n",
    "            \"OLS\": {\"strong\": [], \"weak\": []},\n",
    "            \"E-Net\": {\"strong\": [], \"weak\": []},\n",
    "            \"NN\": {\"strong\": [], \"weak\": []}\n",
    "        }\n",
    "\n",
    "    BOOTSTRAP_R2_RESULTS = {\n",
    "            \"Task Space\": copy.deepcopy(base_results_by_dv),\n",
    "            \"McGrath Categorical\": copy.deepcopy(base_results_by_dv),\n",
    "            \"McGrath Subspace\": copy.deepcopy(base_results_by_dv),\n",
    "            \"Steiner Subspace\": copy.deepcopy(base_results_by_dv),\n",
    "            \"Laughlin Subspace\": copy.deepcopy(base_results_by_dv)\n",
    "        }\n",
    "    BOOTSTRAP_MODELS = copy.deepcopy(BOOTSTRAP_R2_RESULTS)\n",
    "    BOOTSTRAP_RMSE_RESULTS = copy.deepcopy(BOOTSTRAP_R2_RESULTS)\n",
    "\n",
    "# all ways of choosing 5 tasks from df_condition_level_data\n",
    "def get_all_combinations_of_tasks(df, num_tasks=5):\n",
    "    \"\"\"\n",
    "    Get all combinations of tasks from the DataFrame.\n",
    "    \"\"\"\n",
    "    tasks = df['task'].unique()\n",
    "    return list(itertools.combinations(tasks, num_tasks))\n",
    "\n",
    "# Sample a limited number of task combinations\n",
    "all_held_out_options = get_all_combinations_of_tasks(df_condition_level_data, num_tasks=5)\n",
    "random.seed(19104)\n",
    "num_to_sample = 250\n",
    "held_out_sample = random.sample(all_held_out_options, num_to_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting RMSE from a trained model\n",
    "def get_rmse_for_ols_enet(model_ols, model_enet, X_test, y_true, ivs):\n",
    "    \"\"\"\n",
    "    Calculate RMSE for the OLS and E-Net predictions.\n",
    "    \"\"\"\n",
    "    rmse_ols = get_rmse_ols(model_ols, X_test, y_true, ivs)\n",
    "    rmse_enet = get_rmse_for_enet(model_enet, X_test, y_true, ivs)\n",
    "    \n",
    "    return rmse_ols, rmse_enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping R2 Results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:00<00:00, 4298.32it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, held_out_set in enumerate(tqdm(held_out_sample, desc=\"Bootstrapping R2 Results\", total=len(held_out_sample))):\n",
    "    \n",
    "    wave_a_data = df_condition_level_data[~df_condition_level_data[\"task\"].isin(held_out_set)]\n",
    "    wave_b_data = df_condition_level_data[df_condition_level_data[\"task\"].isin(held_out_set)]\n",
    "\n",
    "    for model_type in MODELS.keys():\n",
    "\n",
    "        for dv_type in [\"strong\", \"weak\"]:\n",
    "            if model_type == \"Task Space\":\n",
    "                ivs = basic_IVs\n",
    "            elif model_type == \"McGrath Categorical\":\n",
    "                ivs = categorical_IVs\n",
    "            elif model_type == \"McGrath Subspace\":\n",
    "                ivs = mcgrath_continuous\n",
    "            elif model_type == \"Steiner Subspace\":\n",
    "                ivs = steiner_continuous\n",
    "            elif model_type == \"Laughlin Subspace\":\n",
    "                ivs = laughlin_continuous\n",
    "            else:\n",
    "                raise ValueError(\"Unknown model type: {}\".format(model_type))\n",
    "            \n",
    "\n",
    "            # if the BOOTSTRAP_R2_RESULTS already has a model at this index, skip it\n",
    "            try:\n",
    "                model_ols = BOOTSTRAP_MODELS[model_type][\"OLS\"][dv_type][i]\n",
    "                r2_ols = BOOTSTRAP_MODELS[model_type][\"E-Net\"][dv_type][i]\n",
    "            except IndexError:\n",
    "                \n",
    "                # Train and test OLS model\n",
    "                model_ols, r2_ols = train_wave_a_test_wave_b(\n",
    "                    wave_a_data.copy(), wave_b_data.copy(), dv_type, ivs, f\"{model_type} {dv_type} {held_out_set}\", plot=False\n",
    "                )\n",
    "                # Train and test E-Net model\n",
    "                model_enet, r2_enet = train_wave_a_test_wave_b_enet(\n",
    "                    wave_a_data.copy(), wave_b_data.copy(), dv_type, ivs, f\"{model_type} {dv_type} {held_out_set}\", plot=False\n",
    "                )\n",
    "\n",
    "                # get model rmse on test set\n",
    "                rmse_ols, rmse_enet = get_rmse_for_ols_enet(\n",
    "                    model_ols, model_enet, wave_b_data, wave_b_data[dv_type], ivs\n",
    "                )\n",
    "                \n",
    "                # store the models\n",
    "                BOOTSTRAP_MODELS[model_type][\"OLS\"][dv_type].append(model_ols)\n",
    "                BOOTSTRAP_MODELS[model_type][\"E-Net\"][dv_type].append(model_enet)\n",
    "\n",
    "                # Store the R^2\n",
    "                BOOTSTRAP_R2_RESULTS[model_type][\"OLS\"][dv_type].append(r2_ols)\n",
    "                BOOTSTRAP_R2_RESULTS[model_type][\"E-Net\"][dv_type].append(r2_enet)\n",
    "\n",
    "                # Store the RMSE\n",
    "                BOOTSTRAP_RMSE_RESULTS[model_type][\"OLS\"][dv_type].append(rmse_ols)\n",
    "                BOOTSTRAP_RMSE_RESULTS[model_type][\"E-Net\"][dv_type].append(rmse_enet)\n",
    "\n",
    "                # write to pkl\n",
    "                with open(bootstrap_model_pkl_filename, 'wb') as f:\n",
    "                    pickle.dump(BOOTSTRAP_MODELS, f)\n",
    "                with open(bootstrap_r2_pkl_filename, 'wb') as f:\n",
    "                    pickle.dump(BOOTSTRAP_R2_RESULTS, f)\n",
    "                with open(bootstrap_rmse_pkl_filename, 'wb') as f:\n",
    "                    pickle.dump(BOOTSTRAP_RMSE_RESULTS, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Bootstrap Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise R^2 Summary Table - Strong Group Advantage\n",
      "Model Type                              Comparison  Mean Diff  CI 1.96 Lower  CI 1.96 Upper  CI Percentile Lower  CI Percentile Upper\n",
      "       OLS    Steiner Subspace - Laughlin Subspace   0.880025       0.610838       1.149213            -1.040674             6.424184\n",
      "       OLS McGrath Categorical - Laughlin Subspace   0.594351       0.287168       0.901533            -1.629087             6.678593\n",
      "     E-Net          Task Space - Laughlin Subspace   0.435271       0.294631       0.575911            -0.842967             2.653544\n",
      "     E-Net    McGrath Subspace - Laughlin Subspace   0.380652       0.232142       0.529162            -0.479853             2.504721\n",
      "       OLS  McGrath Categorical - McGrath Subspace   0.301353       0.047260       0.555447            -1.911192             7.156368\n",
      "     E-Net    Steiner Subspace - Laughlin Subspace   0.299934       0.146444       0.453425            -0.920730             2.590392\n",
      "       OLS    McGrath Subspace - Laughlin Subspace   0.292997      -0.052211       0.638205            -4.677030             6.517318\n",
      "     E-Net        Task Space - McGrath Categorical   0.273171       0.159118       0.387225            -2.195947             1.635501\n",
      "     E-Net McGrath Categorical - Laughlin Subspace   0.162099      -0.022138       0.346336            -1.377246             3.590936\n",
      "     E-Net           Task Space - Steiner Subspace   0.135336       0.040959       0.229714            -1.534510             0.891496\n",
      "     E-Net     McGrath Subspace - Steiner Subspace   0.080718      -0.013018       0.174454            -1.031774             1.079031\n",
      "     E-Net           Task Space - McGrath Subspace   0.054618      -0.023760       0.132997            -1.909190             0.936488\n",
      "     E-Net  McGrath Categorical - Steiner Subspace  -0.137835      -0.257730      -0.017940            -1.641283             1.064022\n",
      "     E-Net  McGrath Categorical - McGrath Subspace  -0.218553      -0.307340      -0.129766            -1.504982             1.311387\n",
      "       OLS  McGrath Categorical - Steiner Subspace  -0.285675      -0.424785      -0.146565            -2.413247             1.467342\n",
      "       OLS          Task Space - Laughlin Subspace  -0.467477      -0.803529      -0.131425            -4.453286             4.476948\n",
      "       OLS     McGrath Subspace - Steiner Subspace  -0.587028      -0.818759      -0.355297            -6.469831             1.206241\n",
      "       OLS           Task Space - McGrath Subspace  -0.760474      -1.045967      -0.474981            -5.875146             2.143570\n",
      "       OLS        Task Space - McGrath Categorical  -1.061828      -1.408403      -0.715252            -9.614614             1.076384\n",
      "       OLS           Task Space - Steiner Subspace  -1.347502      -1.661617      -1.033387            -8.563188             0.477294\n",
      "\n",
      "Pairwise R^2 Summary Table - Weak Group Advantage\n",
      "Model Type                              Comparison  Mean Diff  CI 1.96 Lower  CI 1.96 Upper  CI Percentile Lower  CI Percentile Upper\n",
      "       OLS    Steiner Subspace - Laughlin Subspace   3.146917       2.494936       3.798898            -0.125038            19.743795\n",
      "       OLS McGrath Categorical - Laughlin Subspace   2.670143       1.987481       3.352805            -0.706012            20.153267\n",
      "       OLS    McGrath Subspace - Laughlin Subspace   2.169291       1.470692       2.867891            -3.651585            19.504140\n",
      "     E-Net          Task Space - Laughlin Subspace   1.313320       0.821952       1.804687            -0.309268            15.496320\n",
      "     E-Net    Steiner Subspace - Laughlin Subspace   1.215820       0.726807       1.704833            -0.666320            15.509904\n",
      "     E-Net    McGrath Subspace - Laughlin Subspace   0.978598       0.489473       1.467724            -0.819467            14.874434\n",
      "     E-Net McGrath Categorical - Laughlin Subspace   0.927650       0.433681       1.421619            -0.665643            15.430623\n",
      "       OLS          Task Space - Laughlin Subspace   0.540320      -0.088198       1.168838            -6.031034            17.951081\n",
      "       OLS  McGrath Categorical - McGrath Subspace   0.500852       0.148233       0.853471            -1.246521            10.109169\n",
      "     E-Net        Task Space - McGrath Categorical   0.385670       0.319542       0.451797            -0.510239             1.452175\n",
      "     E-Net           Task Space - McGrath Subspace   0.334721       0.268474       0.400968            -0.536144             1.440660\n",
      "     E-Net           Task Space - Steiner Subspace   0.097500       0.056669       0.138331            -0.461549             0.622343\n",
      "     E-Net  McGrath Categorical - McGrath Subspace  -0.050948      -0.123448       0.021552            -0.886270             1.321022\n",
      "     E-Net     McGrath Subspace - Steiner Subspace  -0.237221      -0.304670      -0.169773            -1.260640             0.792889\n",
      "     E-Net  McGrath Categorical - Steiner Subspace  -0.288170      -0.355156      -0.221183            -1.240069             0.677533\n",
      "       OLS  McGrath Categorical - Steiner Subspace  -0.476774      -0.555792      -0.397755            -1.667825             0.880848\n",
      "       OLS     McGrath Subspace - Steiner Subspace  -0.977626      -1.312702      -0.642549           -10.449237             0.781000\n",
      "       OLS           Task Space - McGrath Subspace  -1.628972      -2.027089      -1.230854            -9.604854             2.994528\n",
      "       OLS        Task Space - McGrath Categorical  -2.129824      -2.525421      -1.734226           -11.670941             0.702771\n",
      "       OLS           Task Space - Steiner Subspace  -2.606597      -2.995050      -2.218144           -11.879174             0.178038\n"
     ]
    }
   ],
   "source": [
    "def calculate_pairwise_differences(data1, data2):\n",
    "    differences = np.array(data1) - np.array(data2)\n",
    "    mean_diff = np.mean(differences)\n",
    "    \n",
    "    # 1.96 method for confidence intervals\n",
    "    sem_diff = np.std(differences, ddof=1) / np.sqrt(len(differences))\n",
    "    ci_1_96_lower_diff = mean_diff - 1.96 * sem_diff\n",
    "    ci_1_96_upper_diff = mean_diff + 1.96 * sem_diff\n",
    "    \n",
    "    # Percentile method\n",
    "    ci_percentile_lower_diff = np.percentile(differences, 2.5)\n",
    "    ci_percentile_upper_diff = np.percentile(differences, 97.5)\n",
    "    \n",
    "    return mean_diff, ci_1_96_lower_diff, ci_1_96_upper_diff, ci_percentile_lower_diff, ci_percentile_upper_diff\n",
    "\n",
    "def generate_pairwise_summary_table(bootstrapped_r2_results, dv_choice):\n",
    "    summary_data = []\n",
    "\n",
    "    for model_type in [\"OLS\", \"E-Net\"]:\n",
    "        iv_types = list(bootstrapped_r2_results.keys())\n",
    "        for i, iv_1 in enumerate(iv_types):\n",
    "            if not bootstrapped_r2_results[iv_1][model_type].get(dv_choice, []):\n",
    "                continue\n",
    "            for iv_2 in iv_types[i+1:]:\n",
    "                if not bootstrapped_r2_results[iv_2][model_type].get(dv_choice, []):\n",
    "                    continue\n",
    "                data1 = bootstrapped_r2_results[iv_1][model_type][dv_choice]\n",
    "                data2 = bootstrapped_r2_results[iv_2][model_type][dv_choice]\n",
    "                if data1 and data2:\n",
    "                    (mean_diff, ci_1_96_lower_diff, ci_1_96_upper_diff,\n",
    "                     ci_percentile_lower_diff, ci_percentile_upper_diff) = calculate_pairwise_differences(data1, data2)\n",
    "\n",
    "                    comparison_name = f\"{iv_1} - {iv_2}\"\n",
    "                    summary_data.append({\n",
    "                        'Model Type': model_type,\n",
    "                        'Comparison': comparison_name,\n",
    "                        'Mean Diff': mean_diff,\n",
    "                        'CI 1.96 Lower': ci_1_96_lower_diff,\n",
    "                        'CI 1.96 Upper': ci_1_96_upper_diff,\n",
    "                        'CI Percentile Lower': ci_percentile_lower_diff,\n",
    "                        'CI Percentile Upper': ci_percentile_upper_diff\n",
    "                    })\n",
    "\n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    df_summary.sort_values(by='Mean Diff', ascending=False, inplace=True)\n",
    "    return df_summary\n",
    "\n",
    "# Generate and print tables for both 'strong' and 'weak' DV types\n",
    "pairwise_table_strong = generate_pairwise_summary_table(BOOTSTRAP_R2_RESULTS, 'strong')\n",
    "pairwise_table_weak = generate_pairwise_summary_table(BOOTSTRAP_R2_RESULTS, 'weak')\n",
    "\n",
    "print(\"Pairwise R^2 Summary Table - Strong Group Advantage\")\n",
    "print(pairwise_table_strong.to_string(index=False))\n",
    "print(\"\\nPairwise R^2 Summary Table - Weak Group Advantage\")\n",
    "print(pairwise_table_weak.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise RMSE Summary Table - Strong Group Advantage\n",
      "Model Type                              Comparison  Mean Diff  CI 1.96 Lower  CI 1.96 Upper  CI Percentile Lower  CI Percentile Upper\n",
      "       OLS           Task Space - Steiner Subspace   0.109168       0.093162       0.125174            -0.073827             0.415752\n",
      "       OLS        Task Space - McGrath Categorical   0.063681       0.047049       0.080312            -0.146280             0.393367\n",
      "       OLS           Task Space - McGrath Subspace   0.063477       0.045601       0.081354            -0.232506             0.386947\n",
      "       OLS     McGrath Subspace - Steiner Subspace   0.045691       0.029779       0.061603            -0.143057             0.412425\n",
      "       OLS  McGrath Categorical - Steiner Subspace   0.045487       0.035575       0.055399            -0.103736             0.198898\n",
      "       OLS          Task Space - Laughlin Subspace   0.043429       0.023791       0.063066            -0.278713             0.359387\n",
      "     E-Net  McGrath Categorical - McGrath Subspace   0.038857       0.031062       0.046652            -0.079649             0.156963\n",
      "     E-Net  McGrath Categorical - Steiner Subspace   0.025637       0.018165       0.033110            -0.097070             0.186271\n",
      "     E-Net McGrath Categorical - Laughlin Subspace   0.004642      -0.006020       0.015305            -0.219644             0.159304\n",
      "       OLS  McGrath Categorical - McGrath Subspace  -0.000203      -0.018622       0.018215            -0.364867             0.167943\n",
      "     E-Net     McGrath Subspace - Steiner Subspace  -0.013220      -0.019911      -0.006529            -0.143810             0.077066\n",
      "     E-Net           Task Space - McGrath Subspace  -0.017385      -0.025394      -0.009376            -0.122257             0.129567\n",
      "       OLS    McGrath Subspace - Laughlin Subspace  -0.020049      -0.040523       0.000426            -0.319774             0.386849\n",
      "       OLS McGrath Categorical - Laughlin Subspace  -0.020252      -0.037180      -0.003325            -0.340781             0.180458\n",
      "     E-Net    Steiner Subspace - Laughlin Subspace  -0.020995      -0.030332      -0.011658            -0.227072             0.118544\n",
      "     E-Net           Task Space - Steiner Subspace  -0.030605      -0.038288      -0.022923            -0.137730             0.118711\n",
      "     E-Net    McGrath Subspace - Laughlin Subspace  -0.034215      -0.042831      -0.025599            -0.202199             0.069130\n",
      "     E-Net          Task Space - Laughlin Subspace  -0.051600      -0.061375      -0.041825            -0.235378             0.102520\n",
      "     E-Net        Task Space - McGrath Categorical  -0.056242      -0.065710      -0.046775            -0.200377             0.131507\n",
      "       OLS    Steiner Subspace - Laughlin Subspace  -0.065739      -0.079628      -0.051851            -0.347352             0.110117\n",
      "\n",
      "Pairwise RMSE Summary Table - Weak Group Advantage\n",
      "Model Type                              Comparison  Mean Diff  CI 1.96 Lower  CI 1.96 Upper  CI Percentile Lower  CI Percentile Upper\n",
      "       OLS           Task Space - Steiner Subspace   0.489036       0.438467       0.539605            -0.074917             1.432511\n",
      "       OLS           Task Space - McGrath Subspace   0.322325       0.270495       0.374155            -0.243604             1.093825\n",
      "       OLS        Task Space - McGrath Categorical   0.321410       0.270333       0.372487            -0.290217             1.388844\n",
      "       OLS  McGrath Categorical - Steiner Subspace   0.167626       0.148283       0.186969            -0.155677             0.442667\n",
      "       OLS     McGrath Subspace - Steiner Subspace   0.166711       0.125040       0.208381            -0.169968             1.162733\n",
      "     E-Net  McGrath Categorical - Steiner Subspace   0.102444       0.087450       0.117438            -0.161029             0.317439\n",
      "     E-Net     McGrath Subspace - Steiner Subspace   0.075108       0.058343       0.091872            -0.214155             0.321861\n",
      "     E-Net  McGrath Categorical - McGrath Subspace   0.027337       0.011539       0.043135            -0.285375             0.262693\n",
      "       OLS          Task Space - Laughlin Subspace   0.011484      -0.052588       0.075556            -1.163981             0.871942\n",
      "       OLS  McGrath Categorical - McGrath Subspace   0.000915      -0.045760       0.047590            -1.062334             0.421359\n",
      "     E-Net           Task Space - Steiner Subspace  -0.039297      -0.050233      -0.028361            -0.222038             0.142717\n",
      "     E-Net McGrath Categorical - Laughlin Subspace  -0.086873      -0.131020      -0.042726            -1.494724             0.175054\n",
      "     E-Net    McGrath Subspace - Laughlin Subspace  -0.114210      -0.157013      -0.071407            -1.322175             0.191686\n",
      "     E-Net           Task Space - McGrath Subspace  -0.114405      -0.130339      -0.098471            -0.337567             0.143634\n",
      "     E-Net        Task Space - McGrath Categorical  -0.141742      -0.156681      -0.126802            -0.358498             0.102505\n",
      "     E-Net    Steiner Subspace - Laughlin Subspace  -0.189317      -0.231761      -0.146874            -1.536290             0.187928\n",
      "     E-Net          Task Space - Laughlin Subspace  -0.228614      -0.270980      -0.186249            -1.557848             0.088154\n",
      "       OLS McGrath Categorical - Laughlin Subspace  -0.309926      -0.372308      -0.247544            -1.678147             0.186851\n",
      "       OLS    McGrath Subspace - Laughlin Subspace  -0.310841      -0.376356      -0.245326            -1.663777             0.495890\n",
      "       OLS    Steiner Subspace - Laughlin Subspace  -0.477552      -0.531050      -0.424053            -1.645053             0.026849\n"
     ]
    }
   ],
   "source": [
    "# Generate and print tables for both 'strong' and 'weak' DV types\n",
    "pairwise_table_strong_rmse = generate_pairwise_summary_table(BOOTSTRAP_RMSE_RESULTS, 'strong')\n",
    "pairwise_table_weak_rmse = generate_pairwise_summary_table(BOOTSTRAP_RMSE_RESULTS, 'weak')\n",
    "\n",
    "print(\"Pairwise RMSE Summary Table - Strong Group Advantage\")\n",
    "print(pairwise_table_strong_rmse.to_string(index=False))\n",
    "print(\"\\nPairwise RMSE Summary Table - Weak Group Advantage\")\n",
    "print(pairwise_table_weak_rmse.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Model Predictions with Preregistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Wave 1, Predict on Wave 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_information_wave2 = wave2_df_condition_level_data[[\"task\", \"High\", \"Medium\", \"Low\", \"playerCount\"]]\n",
    "# weak_model_predictions_nn = model_predict(fitted_model = MODELS[\"Task Space NN\"][\"Weak (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t  X = wave2_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t  model_type = \"NN\")\n",
    "# weak_model_predictions_lm = model_predict(fitted_model = MODELS[\"Task Space LM\"][\"Weak (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t  X = wave2_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t  model_type = \"LM\")\n",
    "# strong_model_predictions_nn = model_predict(fitted_model = MODELS[\"Task Space NN\"][\"Strong (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t  X = wave2_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t  model_type = \"NN\")\n",
    "# strong_model_predictions_lm = model_predict(fitted_model = MODELS[\"Task Space LM\"][\"Strong (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t  X = wave2_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t  model_type = \"LM\")\n",
    "# # add the model predictions to the dataframe\n",
    "# task_information_wave2[\"Weak NN Predictions\"] = weak_model_predictions_nn.round(2)\n",
    "# task_information_wave2[\"Weak LM Predictions\"] = weak_model_predictions_lm.round(2)\n",
    "# task_information_wave2[\"Strong NN Predictions\"] = strong_model_predictions_nn.round(2)\n",
    "# task_information_wave2[\"Strong LM Predictions\"] = strong_model_predictions_lm.round(2)\n",
    "# # add the mean of the training data to the dataframe\n",
    "# task_information_wave2[\"Weak Baseline\"] = wave1_df_condition_level_data[\"weak\"].mean().round(2)\n",
    "# task_information_wave2[\"Strong Baseline\"] = wave1_df_condition_level_data[\"strong\"].mean().round(2)\n",
    "\n",
    "# # order the tasks in the following order\n",
    "# order = [\"Logic Problem\", \"Unscramble Words\", \"Random Dot Motion\", \"Recall Word Lists\", \"Typing\"]\n",
    "# task_information_wave2[\"task\"] = pd.Categorical(task_information_wave2[\"task\"], categories=order, ordered=True)\n",
    "# task_information_wave2 = task_information_wave2.sort_values(by=[\"task\",  \"High\", \"Low\", \"Medium\",  \"playerCount\"], ascending=[True, True, False, False, True])\n",
    "# task_information_wave2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# # merge in the original predictions\n",
    "# original_preds_wave2 = pd.read_csv('../original_predictions/wave2_preds.csv').rename(columns={\"Task\": \"task\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Weak_NN\": \"Weak NN Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Strong_NN\": \"Strong NN Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Weak_LM\": \"Weak LM Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Strong_LM\": \"Strong LM Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Weak_Baseline\": \"Weak Baseline Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Strong_Baseline\": \"Strong Baseline Original\"})\n",
    "# # get dummies for complexity in original_preds_wave2 with NO prefix\n",
    "# original_preds_wave2 = pd.get_dummies(original_preds_wave2, columns=[\"Complexity\"], prefix=\"\", prefix_sep=\"\")\n",
    "# task_information_wave2 = pd.merge(task_information_wave2, original_preds_wave2, on=['task', 'High', 'Medium', 'Low', 'playerCount'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_prediction_differences(task_info_df, wave):\n",
    "# \tpred_cols = [\n",
    "# \t\t\"Weak NN Predictions\", \"Weak LM Predictions\",\n",
    "# \t\t\"Strong NN Predictions\", \"Strong LM Predictions\"\n",
    "# \t]\n",
    "# \toriginal_cols = [col + \" Original\" for col in pred_cols]\n",
    "\n",
    "# \ttask_information_long = pd.concat([\n",
    "# \t\tpd.DataFrame({\n",
    "# \t\t\t'task': task_info_df['task'],\n",
    "# \t\t\t'prediction_type': pred,\n",
    "# \t\t\t'Model Predictions': task_info_df[pred],\n",
    "# \t\t\t'Original Predictions': task_info_df[orig]\n",
    "# \t\t})\n",
    "# \t\tfor pred, orig in zip(pred_cols, original_cols)\n",
    "# \t], ignore_index=True)\n",
    "\n",
    "# \tpalette = sns.color_palette(\"viridis\", len(task_info_df['task'].unique()))\n",
    "# \tg = sns.FacetGrid(\n",
    "# \t\ttask_information_long, col='prediction_type', col_wrap=2, height=5, aspect=1, hue='task', palette=palette\n",
    "# \t)\n",
    "# \tg.map_dataframe(sns.scatterplot, x='Model Predictions', y='Original Predictions')\n",
    "\n",
    "# \t# Add diagonal lines\n",
    "# \tfor ax in g.axes.flatten():\n",
    "# \t\tmax_val = max(ax.get_xlim()[1], ax.get_ylim()[1])\n",
    "# \t\tax.plot([0, max_val], [0, max_val], color='red', linestyle='--')\n",
    "\n",
    "# \tg.add_legend(title=\"Task\")\n",
    "# \tg.set_titles(col_template=\"{col_name}\")\n",
    "# \tg.set_axis_labels(\"Model Predictions\", \"Original Predictions\")\n",
    "# \tplt.savefig('../outputs/prediction_differences_wave' + str(wave) + '.png')\n",
    "# \tplt.show()\n",
    "\n",
    "# plot_prediction_differences(task_information_wave2, wave = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Waves 1-2, Predict on Wave 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_information_wave3 = wave3_df_condition_level_data[[\"task\", \"High\", \"Medium\", \"Low\", \"playerCount\"]]\n",
    "# weak_model_predictions_nn = model_predict(fitted_model = MODELS[\"Task Space NN\"][\"Weak (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t\t\t\t\tX = wave3_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t\t\t\t\t\tmodel_type = \"NN\")\n",
    "# weak_model_predictions_lm = model_predict(fitted_model = MODELS[\"Task Space LM\"][\"Weak (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t\t\t\t\tX = wave3_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t\t\t\t\tmodel_type = \"LM\")\n",
    "# strong_model_predictions_nn = model_predict(fitted_model = MODELS[\"Task Space NN\"][\"Strong (Train Waves 1-2, Predict Wave 3)\"],\n",
    "# \t\t\t\t\t\t\t\tX = wave3_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t\t\t\t\t\tmodel_type = \"NN\")\n",
    "# strong_model_predictions_lm = model_predict(fitted_model = MODELS[\"Task Space LM\"][\"Strong (Train Waves 1-2, Predict Wave 3)\"],\n",
    "# \t\t\t\t\t\t\t\tX = wave3_df_condition_level_data[basic_IVs],\n",
    "# \t\t\t\t\t\t\t\tmodel_type = \"LM\")\n",
    "# # add the model predictions to the dataframe\n",
    "# task_information_wave3[\"Weak NN Predictions\"] = weak_model_predictions_nn.round(2)\n",
    "# task_information_wave3[\"Weak LM Predictions\"] = weak_model_predictions_lm.round(2)\n",
    "# task_information_wave3[\"Strong NN Predictions\"] = strong_model_predictions_nn.round(2)\n",
    "# task_information_wave3[\"Strong LM Predictions\"] = strong_model_predictions_lm.round(2)\n",
    "# # add the mean of the training data to the dataframe\n",
    "# task_information_wave3[\"Weak Baseline\"] = wave12_df_condition_level_data[\"weak\"].mean().round(2)\n",
    "# task_information_wave3[\"Strong Baseline\"] = wave12_df_condition_level_data[\"strong\"].mean().round(2)\n",
    "\n",
    "# # order the tasks in the following order\n",
    "# order = [\"Wildcat Wells\", \"WildCam\", \"Recall Association\", \"Advertisement Writing\", \"Putting Food Into Categories\"]\n",
    "# task_information_wave3[\"task\"] = pd.Categorical(task_information_wave3[\"task\"], categories=order, ordered=True)\n",
    "# task_information_wave3 = task_information_wave3.sort_values(by=[\"task\",  \"High\", \"Low\", \"Medium\",  \"playerCount\"], ascending=[True, True, False, False, True])\n",
    "# task_information_wave3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # merge in the original predictions\n",
    "# original_preds_wave3 = pd.read_csv('../original_predictions/wave3_preds.csv').rename(columns={\"Task\": \"task\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Weak_NN\": \"Weak NN Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Strong_NN\": \"Strong NN Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Weak_LM\": \"Weak LM Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Strong_LM\": \"Strong LM Predictions Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Weak_Baseline\": \"Weak Baseline Original\",\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \"Strong_Baseline\": \"Strong Baseline Original\"})\n",
    "# original_preds_wave3 = pd.get_dummies(original_preds_wave3, columns=[\"Complexity\"], prefix=\"\", prefix_sep=\"\")\n",
    "# task_information_wave3 = pd.merge(task_information_wave3, original_preds_wave3, on=['task', 'High', 'Medium', 'Low', 'playerCount'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_prediction_differences(task_information_wave3, wave = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for New Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_future_tasks = pd.read_csv('../future_predictions/future_tasks_for_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weak_model_predictions_nn_future = model_predict(fitted_model = MODELS[\"Task Space NN\"][\"Weak (Train Wave 1, Predict Wave 2)\"], \n",
    "# \t\t\t\t\t\t\tX = df_future_tasks[basic_IVs],\n",
    "# \t\t\t\t\t\t\t\tmodel_type = \"NN\")\n",
    "# strong_model_predictions_nn_future = model_predict(fitted_model = MODELS[\"Task Space NN\"][\"Strong (Train Waves 1-2, Predict Wave 3)\"],\n",
    "# \t\t\t\t\t\t\t\tX = df_future_tasks[basic_IVs],\n",
    "# \t\t\t\t\t\t\t\tmodel_type = \"NN\")\n",
    "\n",
    "# future_predictions =  df_future_tasks[[\"task\", \"High\", \"Medium\", \"Low\", \"playerCount\"]]\n",
    "# # append the future predictions as \"strong_prediction\" and \"weak_prediction\"\n",
    "# future_predictions[\"Weak Prediction\"] = weak_model_predictions_nn_future.round(2)\n",
    "# future_predictions[\"Strong Prediction\"] = strong_model_predictions_nn_future.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future_predictions.to_csv('../future_predictions/future_tasks_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synergy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
